<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000">
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top">
  
  
  <title>[神经网络与深度学习][2][机器学习概述] | T0UGU BLOG</title>
  <meta name="description" content="第2章 机器学习概述  机器学习是对能通过经验自动改进的计算机算法的研究．——汤姆·米切尔（Tom Mitchell）  机器学习（Machine Learning，ML）就是让计算机从数据中进行自动学习，得到某种知识（或规律）.即如何从观测数据（样本）中寻找规律，并利用学习到的规律（模型）对未知或无法观测的数据进行预测． 机器学习任务的特点是，对于我们人类而言，这些任务很容易完成，但我们不知道">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="[神经网络与深度学习][2][机器学习概述]">
<meta property="og:url" content="https://t0ugh.biz/2020/10/15/神经网络与深度学习-2-机器学习概述/index.html">
<meta property="og:site_name" content="打怪升级日常">
<meta property="og:description" content="第2章 机器学习概述  机器学习是对能通过经验自动改进的计算机算法的研究．——汤姆·米切尔（Tom Mitchell）  机器学习（Machine Learning，ML）就是让计算机从数据中进行自动学习，得到某种知识（或规律）.即如何从观测数据（样本）中寻找规律，并利用学习到的规律（模型）对未知或无法观测的数据进行预测． 机器学习任务的特点是，对于我们人类而言，这些任务很容易完成，但我们不知道">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://i.loli.net/2020/09/10/gZGz83Slp9Pf7ix.png">
<meta property="og:image" content="https://i.loli.net/2020/09/10/bhSn164EtPdDgf5.png">
<meta property="og:image" content="https://i.loli.net/2020/09/10/F874opJIgihvNV2.png">
<meta property="og:image" content="https://i.loli.net/2020/09/10/slahkmPMzwZrx7W.png">
<meta property="og:image" content="https://i.loli.net/2020/09/10/B8F51CVfmjJZD9l.png">
<meta property="og:image" content="https://i.loli.net/2020/09/10/ydDMrKphcGzWUHn.png">
<meta property="og:image" content="https://i.loli.net/2020/09/10/d9y3htzu8BCwDgO.png">
<meta property="og:image" content="https://t0ugh.biz/2020/10/15/神经网络与深度学习-2-机器学习概述/C:%5CUsers%5CMSI-NB%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200911154649100.png">
<meta property="og:image" content="https://t0ugh.biz/2020/10/15/神经网络与深度学习-2-机器学习概述/C:%5CUsers%5CMSI-NB%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200911155426506.png">
<meta property="og:image" content="https://t0ugh.biz/2020/10/15/神经网络与深度学习-2-机器学习概述/C:%5CUsers%5CMSI-NB%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200911161807338.png">
<meta property="og:image" content="https://t0ugh.biz/2020/10/15/神经网络与深度学习-2-机器学习概述/C:%5CUsers%5CMSI-NB%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200911161941823.png">
<meta property="og:image" content="https://i.loli.net/2020/09/12/akQsyMEFw1THSh7.png">
<meta property="og:image" content="https://i.loli.net/2020/09/12/akQsyMEFw1THSh7.png">
<meta property="og:image" content="https://t0ugh.biz/2020/10/15/神经网络与深度学习-2-机器学习概述/C:%5CUsers%5CMSI-NB%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200912093218749.png">
<meta property="og:image" content="https://i.loli.net/2020/09/12/PAJQW9vzeqaM43y.png">
<meta property="og:image" content="https://i.loli.net/2020/09/12/ix79b5HkJPw1K8o.png">
<meta property="og:image" content="https://i.loli.net/2020/09/12/OGKcky8ItA1QCvd.png">
<meta property="og:image" content="https://i.loli.net/2020/09/12/kXP5zW2icsgIOma.png">
<meta property="og:image" content="https://i.loli.net/2020/09/12/lokqjURaQbEGe3z.png">
<meta property="og:updated_time" content="2020-11-10T11:02:48.130Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="[神经网络与深度学习][2][机器学习概述]">
<meta name="twitter:description" content="第2章 机器学习概述  机器学习是对能通过经验自动改进的计算机算法的研究．——汤姆·米切尔（Tom Mitchell）  机器学习（Machine Learning，ML）就是让计算机从数据中进行自动学习，得到某种知识（或规律）.即如何从观测数据（样本）中寻找规律，并利用学习到的规律（模型）对未知或无法观测的数据进行预测． 机器学习任务的特点是，对于我们人类而言，这些任务很容易完成，但我们不知道">
<meta name="twitter:image" content="https://i.loli.net/2020/09/10/gZGz83Slp9Pf7ix.png">
  <!-- Canonical links -->
  <link rel="canonical" href="https://t0ugh.biz/2020/10/15/神经网络与深度学习-2-机器学习概述/index.html">
  
    <link rel="alternate" href="/atom.xml" title="打怪升级日常" type="application/atom+xml">
  
  
    <link rel="icon" href="https://i.loli.net/2020/03/21/WAKimNUecFR64uo.jpg" type="image/x-icon">
  
  <link rel="stylesheet" href="/css/style.css">
  
    <link href="//cdn.jsdelivr.net/npm/katex@0.9.0/dist/katex.min.css" rel="stylesheet">
  
  
  
  
</head>


<body class="main-center" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope="" itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="https://github.com/t0ugh" target="_blank">
          <img class="img-circle img-rotate" src="https://i.loli.net/2020/03/21/WAKimNUecFR64uo.jpg" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">T0UGH</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md">学生&amp;编程爱好者</h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> ShenYang, China</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="Search">
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="Type something..." x-webkit-speech="">
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope="" itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav ">
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <i class="icon icon-home-fill"></i>
            
            <span class="menu-title">Home</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-about">
          <a href="/about">
            
            <i class="icon icon-cup-fill"></i>
            
            <span class="menu-title">About</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            
            <i class="icon icon-archives-fill"></i>
            
            <span class="menu-title">Archives</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories">
            
            <i class="icon icon-folder"></i>
            
            <span class="menu-title">Categories</span>
          </a>
        </li>
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags">
            
            <i class="icon icon-tags"></i>
            
            <span class="menu-title">Tags</span>
          </a>
        </li>
        
      </ul>
      
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/t0ugh" target="_blank" title="Github" data-toggle="tooltip" data-placement="top"><i class="icon icon-github"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" data-toggle="tooltip" data-placement="top"><i class="icon icon-rss"></i></a></li>
        
    </ul>

    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope="" itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">Board</h3>
    <div class="widget-body">
        <div id="board">
            <div class="content">
                <p>东北大学软件工程本科在读</p><p>我的邮箱:wang.g.p@foxmail.com</p>
            </div>
        </div>
    </div>
</div>

    
      
  <div class="widget">
    <h3 class="widget-title">Categories</h3>
    <div class="widget-body">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/C/">C++</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Docker/">Docker</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Flink/">Flink</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/GitHub/">GitHub</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/JavaScript/">JavaScript</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Junit/">Junit</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/MyBatis/">MyBatis</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/MySQL/">MySQL</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/SSM/">SSM</a><span class="category-list-count">12</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/SpringBoot/">SpringBoot</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tensorflow/">Tensorflow</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/c/">c</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/jvm/">jvm</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/linux/vim/">vim</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/nlp/">nlp</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/other/">other</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/redis/">redis</a><span class="category-list-count">12</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/vue/">vue</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/微服务设计/">微服务设计</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/敏捷开发/">敏捷开发</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据结构/">数据结构</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/流畅的Python/">流畅的Python</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/深度学习/">深度学习</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法导论/">算法导论</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/蓝桥杯/">蓝桥杯</a><span class="category-list-count">2</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">Tags</h3>
    <div class="widget-body">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AOP/">AOP</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C++</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN/">CNN</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Docker/">Docker</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ES6/">ES6</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Flink/">Flink</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Git/">Git</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GitHub/">GitHub</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GithubFlow/">GithubFlow</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JAVA/">JAVA</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JavaScript/">JavaScript</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Junit/">Junit</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LSTM/">LSTM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MNIST/">MNIST</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MongoDB/">MongoDB</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MyBatis/">MyBatis</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MySQL/">MySQL</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/">NLP</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a><span class="tag-list-count">11</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/REST/">REST</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RNN/">RNN</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Redis/">Redis</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Scrum/">Scrum</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spring/">Spring</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SpringBoot/">SpringBoot</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SpringCloud/">SpringCloud</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SpringMVC/">SpringMVC</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tensorflow/">Tensorflow</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/YAML/">YAML</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/aof/">aof</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/c/">c</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jvm/">jvm</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nlp/">nlp</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rdb/">rdb</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/redis/">redis</a><span class="tag-list-count">12</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vue/">vue</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/中文分词/">中文分词</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/关键词提取/">关键词提取</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分治算法/">分治算法</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/动态规划/">动态规划</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/大数据/">大数据</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/微服务/">微服务</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/微服务设计/">微服务设计</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/排序/">排序</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/敏捷原则/">敏捷原则</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/敏捷宣言/">敏捷宣言</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/敏捷开发/">敏捷开发</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据库事务/">数据库事务</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据结构/">数据结构</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/流处理/">流处理</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/深度学习/">深度学习</a><span class="tag-list-count">10</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/神经网络/">神经网络</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/算法/">算法</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/算法导论/">算法导论</a><span class="tag-list-count">9</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/蓝桥杯/">蓝桥杯</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/词性标注/">词性标注</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/贪心算法/">贪心算法</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/软件测试/">软件测试</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget-body tagcloud">
      <a href="/tags/AOP/" style="font-size: 13px;">AOP</a> <a href="/tags/C/" style="font-size: 13.18px;">C++</a> <a href="/tags/CNN/" style="font-size: 13px;">CNN</a> <a href="/tags/Docker/" style="font-size: 13.18px;">Docker</a> <a href="/tags/ES6/" style="font-size: 13px;">ES6</a> <a href="/tags/Flink/" style="font-size: 13.45px;">Flink</a> <a href="/tags/Git/" style="font-size: 13px;">Git</a> <a href="/tags/GitHub/" style="font-size: 13.18px;">GitHub</a> <a href="/tags/GithubFlow/" style="font-size: 13px;">GithubFlow</a> <a href="/tags/JAVA/" style="font-size: 13px;">JAVA</a> <a href="/tags/JavaScript/" style="font-size: 13.18px;">JavaScript</a> <a href="/tags/Junit/" style="font-size: 13px;">Junit</a> <a href="/tags/LSTM/" style="font-size: 13px;">LSTM</a> <a href="/tags/MNIST/" style="font-size: 13px;">MNIST</a> <a href="/tags/MongoDB/" style="font-size: 13px;">MongoDB</a> <a href="/tags/MyBatis/" style="font-size: 14px;">MyBatis</a> <a href="/tags/MySQL/" style="font-size: 13.27px;">MySQL</a> <a href="/tags/NLP/" style="font-size: 13px;">NLP</a> <a href="/tags/Python/" style="font-size: 13.82px;">Python</a> <a href="/tags/REST/" style="font-size: 13px;">REST</a> <a href="/tags/RNN/" style="font-size: 13.09px;">RNN</a> <a href="/tags/Redis/" style="font-size: 13.18px;">Redis</a> <a href="/tags/Scrum/" style="font-size: 13.09px;">Scrum</a> <a href="/tags/Spring/" style="font-size: 13.27px;">Spring</a> <a href="/tags/SpringBoot/" style="font-size: 13.55px;">SpringBoot</a> <a href="/tags/SpringCloud/" style="font-size: 13.09px;">SpringCloud</a> <a href="/tags/SpringMVC/" style="font-size: 13.18px;">SpringMVC</a> <a href="/tags/Tensorflow/" style="font-size: 13.55px;">Tensorflow</a> <a href="/tags/YAML/" style="font-size: 13px;">YAML</a> <a href="/tags/aof/" style="font-size: 13px;">aof</a> <a href="/tags/c/" style="font-size: 13px;">c</a> <a href="/tags/java/" style="font-size: 13.64px;">java</a> <a href="/tags/jvm/" style="font-size: 13.45px;">jvm</a> <a href="/tags/linux/" style="font-size: 13px;">linux</a> <a href="/tags/nlp/" style="font-size: 13.18px;">nlp</a> <a href="/tags/rdb/" style="font-size: 13px;">rdb</a> <a href="/tags/redis/" style="font-size: 13.91px;">redis</a> <a href="/tags/vue/" style="font-size: 13.09px;">vue</a> <a href="/tags/中文分词/" style="font-size: 13px;">中文分词</a> <a href="/tags/关键词提取/" style="font-size: 13px;">关键词提取</a> <a href="/tags/分治算法/" style="font-size: 13px;">分治算法</a> <a href="/tags/动态规划/" style="font-size: 13.18px;">动态规划</a> <a href="/tags/大数据/" style="font-size: 13.45px;">大数据</a> <a href="/tags/微服务/" style="font-size: 13.36px;">微服务</a> <a href="/tags/微服务设计/" style="font-size: 13.36px;">微服务设计</a> <a href="/tags/排序/" style="font-size: 13.18px;">排序</a> <a href="/tags/敏捷原则/" style="font-size: 13px;">敏捷原则</a> <a href="/tags/敏捷宣言/" style="font-size: 13px;">敏捷宣言</a> <a href="/tags/敏捷开发/" style="font-size: 13.27px;">敏捷开发</a> <a href="/tags/数据库事务/" style="font-size: 13.09px;">数据库事务</a> <a href="/tags/数据结构/" style="font-size: 13.36px;">数据结构</a> <a href="/tags/机器学习/" style="font-size: 13px;">机器学习</a> <a href="/tags/流处理/" style="font-size: 13.45px;">流处理</a> <a href="/tags/深度学习/" style="font-size: 13.73px;">深度学习</a> <a href="/tags/神经网络/" style="font-size: 13px;">神经网络</a> <a href="/tags/算法/" style="font-size: 13.09px;">算法</a> <a href="/tags/算法导论/" style="font-size: 13.64px;">算法导论</a> <a href="/tags/蓝桥杯/" style="font-size: 13.09px;">蓝桥杯</a> <a href="/tags/词性标注/" style="font-size: 13px;">词性标注</a> <a href="/tags/贪心算法/" style="font-size: 13px;">贪心算法</a> <a href="/tags/软件测试/" style="font-size: 13px;">软件测试</a>
    </div>
  </div>

    
      
  <div class="widget">
    <h3 class="widget-title">Archive</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/11/">November 2020</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/10/">October 2020</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a><span class="archive-list-count">20</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/02/">February 2020</a><span class="archive-list-count">40</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/12/">December 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">June 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/05/">May 2019</a><span class="archive-list-count">9</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a><span class="archive-list-count">19</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">2</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget-body">
      <ul class="recent-post-list list-unstyled no-thumbnail">
        
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/Flink/">Flink</a>
              </p>
              <p class="item-title">
                <a href="/2020/11/11/Flink-6-基于时间和窗口的算子/" class="title">[Flink][6][基于时间和窗口的算子]</a>
              </p>
              <p class="item-date">
                <time datetime="2020-11-11T05:56:49.000Z" itemprop="datePublished">2020-11-11</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/Flink/">Flink</a>
              </p>
              <p class="item-title">
                <a href="/2020/11/08/Flink-5-DataStreamAPI/" class="title">[Flink][5][DataStreamAPI]</a>
              </p>
              <p class="item-date">
                <time datetime="2020-11-08T11:09:54.000Z" itemprop="datePublished">2020-11-08</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/Flink/">Flink</a>
              </p>
              <p class="item-title">
                <a href="/2020/11/02/Flink-4-设置Flink开发环境/" class="title">[Flink][4][设置Flink开发环境]</a>
              </p>
              <p class="item-date">
                <time datetime="2020-11-02T11:08:53.000Z" itemprop="datePublished">2020-11-02</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/Flink/">Flink</a>
              </p>
              <p class="item-title">
                <a href="/2020/11/01/Flink-3-ApacheFlink架构/" class="title">[Flink][3][ApacheFlink架构]</a>
              </p>
              <p class="item-date">
                <time datetime="2020-11-01T11:08:14.000Z" itemprop="datePublished">2020-11-01</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                <a class="category-link" href="/categories/Flink/">Flink</a>
              </p>
              <p class="item-title">
                <a href="/2020/10/30/Flink-2-流处理基础/" class="title">[Flink][2][流处理基础]</a>
              </p>
              <p class="item-date">
                <time datetime="2020-10-30T11:07:33.000Z" itemprop="datePublished">2020-10-30</time>
              </p>
            </div>
          </li>
          
      </ul>
    </div>
  </div>
  

    
  </div>
</aside>

  
  
<main class="main" role="main">
  <div class="content">
    <article id="post-神经网络与深度学习-2-机器学习概述" class="article article-type-post" itemscope="" itemtype="http://schema.org/BlogPosting">
        
            <div class="article-header">
                
                    
  
    <h1 class="article-title" itemprop="name">
      [神经网络与深度学习][2][机器学习概述]
    </h1>
  

                        
                            <div class="article-meta">
                                <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2020/10/15/神经网络与深度学习-2-机器学习概述/" class="article-date">
	  <time datetime="2020-10-15T12:48:57.000Z" itemprop="datePublished">2020-10-15</time>
	</a>
</span>
                                    
  <span class="article-category">
    <i class="icon icon-folder"></i>
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>
  </span>

                                        
  <span class="article-tag">
    <i class="icon icon-tags"></i>
	<a class="article-tag-link" href="/tags/机器学习/">机器学习</a>
  </span>


                                            

                                                <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2020/10/15/神经网络与深度学习-2-机器学习概述/#comments" class="article-comment-link">Comments</a></span>
                                                
                            </div>
            </div>
            <div class="article-entry marked-body" itemprop="articleBody">
                
                                    
                                        <div id="toc">
                                            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#第2章-机器学习概述"><span class="toc-text"> 第2章 机器学习概述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#21-基本概念"><span class="toc-text"> 2.1 基本概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-机器学习的三个基本要素"><span class="toc-text"> 2.2 机器学习的三个基本要素</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#221-模型"><span class="toc-text"> 2.2.1 模型</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2211-线性模型"><span class="toc-text"> 2.2.1.1 线性模型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2212-非线性模型"><span class="toc-text"> 2.2.1.2 非线性模型</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#222-学习准则"><span class="toc-text"> 2.2.2 学习准则</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2221-损失函数"><span class="toc-text"> 2.2.2.1 损失函数</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#0-1损失函数"><span class="toc-text"> 0-1损失函数</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#平方损失函数"><span class="toc-text"> 平方损失函数</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#交叉熵损失函数"><span class="toc-text"> 交叉熵损失函数</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#hinge损失函数"><span class="toc-text"> Hinge损失函数</span></a></li></ol></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2222-风险最小化准则"><span class="toc-text"> 2.2.2.2 风险最小化准则</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#223-优化算法"><span class="toc-text"> 2.2.3 优化算法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2231-梯度下降法"><span class="toc-text"> 2.2.3.1 梯度下降法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2232-提前停止"><span class="toc-text"> 2.2.3.2 提前停止</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2233-随机梯度下降法"><span class="toc-text"> 2.2.3.3 随机梯度下降法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2234-小批量梯度下降法"><span class="toc-text"> 2.2.3.4 小批量梯度下降法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#23-机器学习的简单示例线性回归"><span class="toc-text"> 2.3 机器学习的简单示例——线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#231-参数学习"><span class="toc-text"> 2.3.1 参数学习</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2311-经验风险最小化"><span class="toc-text"> 2.3.1.1 经验风险最小化</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2312-结构风险最小化"><span class="toc-text"> 2.3.1.2 结构风险最小化</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2313-最大似然估计"><span class="toc-text"> 2.3.1.3 最大似然估计</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2314-最大后验估计"><span class="toc-text"> 2.3.1.4 最大后验估计</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#24-偏差-方差分解"><span class="toc-text"> 2.4 偏差-方差分解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#25-机器学习算法的类型"><span class="toc-text"> 2.5 机器学习算法的类型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#251-监督学习"><span class="toc-text"> 2.5.1 监督学习</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#252-无监督学习"><span class="toc-text"> 2.5.2 无监督学习</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#253-强化学习"><span class="toc-text"> 2.5.3 强化学习</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#26-数据的特征表示"><span class="toc-text"> 2.6 数据的特征表示</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#261-图像特征"><span class="toc-text"> 2.6.1 图像特征</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#262-文本特征"><span class="toc-text"> 2.6.2 文本特征</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#263表示学习"><span class="toc-text"> 2.6.3表示学习</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#264-传统的特征学习"><span class="toc-text"> 2.6.4 传统的特征学习</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2641-特征选择"><span class="toc-text"> 2.6.4.1 特征选择</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2642-特征抽取"><span class="toc-text"> 2.6.4.2 特征抽取</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#265-深度学习方法"><span class="toc-text"> 2.6.5 深度学习方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#27-评判标准"><span class="toc-text"> 2.7 评判标准</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#271-准确率"><span class="toc-text"> 2.7.1 准确率</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#272-错误率"><span class="toc-text"> 2.7.2 错误率</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#273-精确率和召回率"><span class="toc-text"> 2.7.3 精确率和召回率</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#274-宏平均和微平均"><span class="toc-text"> 2.7.4 宏平均和微平均</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#275-交叉验证"><span class="toc-text"> 2.7.5 交叉验证</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#28-理论和定理"><span class="toc-text"> 2.8 理论和定理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#281-pac学习理论"><span class="toc-text"> 2.8.1 PAC学习理论</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#282-没有免费的午餐定理"><span class="toc-text"> 2.8.2 没有免费的午餐定理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#283-奥卡姆剃刀原理"><span class="toc-text"> 2.8.3 奥卡姆剃刀原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#284-丑小鸭定理"><span class="toc-text"> 2.8.4 丑小鸭定理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#285-归纳偏置"><span class="toc-text"> 2.8.5 归纳偏置</span></a></li></ol></li></ol></li></ol>
                                        </div>
                                        
                                            <h2 id="第2章-机器学习概述"><a class="markdownIt-Anchor" href="#第2章-机器学习概述"></a> 第2章 机器学习概述</h2>
<blockquote>
<p>机器学习是对能通过经验自动改进的计算机算法的研究．——汤姆·米切尔（Tom Mitchell）</p>
</blockquote>
<p><strong>机器学习</strong>（Machine Learning，ML）就是让计算机<strong>从数据中进行自动学习</strong>，得到某种知识（或规律）.即如何从观测数据（样本）中<strong>寻找规律</strong>，并利用学习到的规律（模型）对未知或无法观测的数据进行<strong>预测</strong>．</p>
<p>机器学习任务的特点是，<strong>对于</strong>我们<strong>人类</strong>而言，这些任务很<strong>容易完成</strong>，但我们<strong>不知道</strong>自己是<strong>如何做到</strong>的，因此也很<strong>难</strong>人工<strong>设计</strong>一个计算机<strong>程序</strong>来完成这些任务．一个可行的方法是设计一个<strong>算法</strong>可以让计算机自己从<strong>有标注的样本</strong>上<strong>学习</strong>其中的规律，并用来完成各种识别任务．</p>
<p>以手写数字识别为例子：要识别手写体数字，<strong>首先</strong>通过<strong>人工标注</strong>大量的手写体数字图像（即每张图像都通过人工标记了它是什么数字），这些图像作为训练数据，<strong>然后</strong>通过学习<strong>算法</strong>自动生成一套<strong>模型</strong>，并依靠它来识别新的手写体数字．这个过程和人类学习过程也比较类似，我们教小孩子识别数字也是这样的过程．这种<strong>通过数据来学习的方法就称为机器学习的方法</strong>．</p>
<h3 id="21-基本概念"><a class="markdownIt-Anchor" href="#21-基本概念"></a> 2.1 基本概念</h3>
<p>首先我们以一个生活中的例子来介绍<strong>机器学习</strong>中的一些<strong>基本概念</strong>：<strong>样本</strong>、<strong>特征</strong>、<strong>标签</strong>、<strong>模型</strong>、<strong>学习算法</strong>等．</p>
<p>首先，我们从市场上随机选取一些芒果，列出每个芒果的<strong>特征（Feature）</strong>，包括颜色、大小、形状、产地、品牌，以及我们需要预测的<strong>标签</strong>（Label）．标签可以是<strong>连续值</strong>（比如关于芒果的甜度、水分以及成熟度的综合打分），也可以是<strong>离散值</strong>（比如“好”“坏”两类标签）</p>
<p>我们可以将一个标记好<strong>特征</strong>以及<strong>标签</strong>的芒果看作一个<strong>样本</strong>（Sample）一组样本构成的集合称为数据集（Data Set）． 一般将<strong>数据集</strong>分为<strong>两部分</strong>：<strong>训练集</strong>和<strong>测试集</strong>．<strong>训练集</strong>（Training Set）中的样本是用来<strong>训练模型</strong>的，也叫训练样本（Training Sample），而<strong>测试集</strong>（Test Set）中的样本是<strong>用来检验模型好坏</strong>的，也叫测试样本（Test Sample）．</p>
<p>我们通常用一个<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span></span></span></span>维向量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="bold-italic">x</mi><mo>=</mo><mo stretchy="false">[</mo><msup><mi>𝑥</mi><mn>1</mn></msup><mo separator="true">,</mo><msup><mi>𝑥</mi><mn>2</mn></msup><mo separator="true">,</mo><mo>⋯</mo><mo separator="true">,</mo><msup><mi>𝑥</mi><mi>D</mi></msup><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\boldsymbol x = [𝑥^1, 𝑥^2, ⋯ , 𝑥^D]^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.44444em;vertical-align:0em;"></span><span class="mord"><span class="mord boldsymbol">x</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span> 表示一个芒果的所有特征构成的向量，称为<strong>特征向量</strong>（Feature Vector），其中每一维表示一个特征．而芒果的<strong>标签</strong>通常用<strong>标量</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑦</mi></mrow><annotation encoding="application/x-tex">𝑦</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span>来表示．</p>
<p>假设训练集<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span></span></span></span>由<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span>个样本组成，其中每个样本都是<strong>独立同分布</strong>的（Identically and Independently Distributed，IID），即独立地从相同的数据分布中抽取的，记为</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mo>=</mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>𝑦</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo separator="true">,</mo><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>𝑦</mi><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>⋯</mo><mo separator="true">,</mo><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">(</mo><mi>𝑁</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>𝑦</mi><mo stretchy="false">(</mo><mi>𝑁</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">D = {(x(1), 𝑦(1)), (𝒙(2), 𝑦(2)), ⋯ , (𝒙(𝑁), 𝑦(𝑁))}.
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mopen">(</span><span class="mord">2</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord">2</span><span class="mclose">)</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mclose">)</span><span class="mclose">)</span></span><span class="mord">.</span></span></span></span></span></p>
<p>给定训练集𝒟，我们希望让计算机从一个函数集合<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo>=</mo><mrow><mi>f</mi><mn>1</mn><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>f</mi><mn>2</mn><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>⋯</mo></mrow></mrow><annotation encoding="application/x-tex">F = {f1(x), f2(x), ⋯}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord">1</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord">2</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">⋯</span></span></span></span></span> 中自动寻找一个“最优”的函数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>f</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f^*(𝒙)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose">)</span></span></span></span> 来近似每个样本的特征向量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝒙</mi></mrow><annotation encoding="application/x-tex">𝒙</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.44444em;vertical-align:0em;"></span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span></span></span></span>和标签<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑦</mi></mrow><annotation encoding="application/x-tex">𝑦</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span>之间的真实映射关系．对于一个样本<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝒙</mi></mrow><annotation encoding="application/x-tex">𝒙</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.44444em;vertical-align:0em;"></span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span></span></span></span>，我们可以通过函数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>𝑓</mi><mi mathvariant="normal">∗</mi></msup><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">𝑓^∗(𝒙)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose">)</span></span></span></span> 来预测其标签的值</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>=</mo><msup><mi>f</mi><mi mathvariant="normal">∗</mi></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat y = f^∗(x)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span></span></p>
<p>如何寻找这个“最优”的函数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>f</mi><mi mathvariant="normal">∗</mi></msup><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f^∗(𝒙)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose">)</span></span></span></span> 是机器学习的关键，一般需要通过学习算法（Learning Algorithm）<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">A</span></span></span></span>来完成．这个寻找过程通常称为学习（Learning）或训练（Training）过程．</p>
<p>为了评价的公正性，我们还是<strong>独立同分布</strong>地抽取一组芒果作为<strong>测试集</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mi mathvariant="normal">′</mi></mrow><annotation encoding="application/x-tex">D′</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord">′</span></span></span></span>，并在<strong>测试集</strong>中所有芒果上进行<strong>测试</strong>，计算<strong>预测结果的准确率</strong></p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝐴</mi><mi>𝑐</mi><mi>𝑐</mi><mo stretchy="false">(</mo><msup><mi>𝑓</mi><mi mathvariant="normal">∗</mi></msup><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mi mathvariant="normal">∣</mi><mi>D</mi><mi mathvariant="normal">′</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><munder><mo>∑</mo><mrow><mo stretchy="false">(</mo><mi>𝒙</mi><mo separator="true">,</mo><mi>𝑦</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>D</mi><mi mathvariant="normal">′</mi></mrow></munder><mi>I</mi><mo stretchy="false">(</mo><msup><mi>f</mi><mi mathvariant="normal">∗</mi></msup><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo><mo>=</mo><mi>𝑦</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">𝐴𝑐𝑐(𝑓^∗(𝒙)) = \frac{1} {|D′|} \sum_{(𝒙,𝑦)∈D′}I(f^∗(𝒙) = 𝑦)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">A</span><span class="mord mathdefault">c</span><span class="mord mathdefault">c</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.8374449999999998em;vertical-align:-1.516005em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord">′</span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.808995em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord boldsymbol mtight" style="margin-right:0.12583em;">x</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mclose mtight">)</span><span class="mrel mtight">∈</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span><span class="mord mtight">′</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516005em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span></span></p>
<p>其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>I</mi><mo stretchy="false">(</mo><mi mathvariant="normal">.</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">I(.)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord">.</span><span class="mclose">)</span></span></span></span>为指示函数，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">∣</mi><mi>D</mi><mi mathvariant="normal">′</mi><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">|D′|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord">′</span><span class="mord">∣</span></span></span></span>为测试集的大小</p>
<p><strong>图2.2</strong>给出了机器学习的基本流程．对一个<strong>预测任务</strong>，<strong>输入特征向量</strong>为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>，<strong>输出标签</strong>为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span>，我们选择一个<strong>函数集合</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi></mrow><annotation encoding="application/x-tex">F</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span></span></span></span>，通过<strong>学习算法</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">A</span></span></span></span>和一组<strong>训练样本</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span></span></span></span>，从<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi></mrow><annotation encoding="application/x-tex">F</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span></span></span></span>中<strong>学习到函数</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>f</mi><mi mathvariant="normal">∗</mi></msup><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f^∗(𝒙)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose">)</span></span></span></span>．这样对新的输入<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>，就可以<strong>用函数</strong> $ f^∗(𝒙)$进行<strong>预测</strong>．</p>
<p><img src="https://i.loli.net/2020/09/10/gZGz83Slp9Pf7ix.png" alt=""></p>
<h3 id="22-机器学习的三个基本要素"><a class="markdownIt-Anchor" href="#22-机器学习的三个基本要素"></a> 2.2 机器学习的三个基本要素</h3>
<p>机器学习方法可以粗略地分为三个<strong>基本要素</strong>：<strong>模型</strong>、<strong>学习准则</strong>、<strong>优化算法</strong>．</p>
<h4 id="221-模型"><a class="markdownIt-Anchor" href="#221-模型"></a> 2.2.1 模型</h4>
<p>对于一个机器学习任务，首先要确定其<strong>输入空间</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span> 和<strong>输出空间</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span>．不同<strong>机器学习任务</strong>的主要<strong>区别</strong>在于<strong>输出空间不同</strong>．在二分类问题中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><mrow><mo>+</mo><mn>1</mn><mo separator="true">,</mo><mi mathvariant="normal">−</mi><mn>1</mn></mrow></mrow><annotation encoding="application/x-tex">y = {+1, −1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord">+</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">−</span><span class="mord">1</span></span></span></span></span>，在𝐶 分类问题中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><mrow><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mo>⋯</mo><mo separator="true">,</mo><mi>C</mi></mrow></mrow><annotation encoding="application/x-tex">y = {1, 2, ⋯ , C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span></span>，而在回归问题中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><mi mathvariant="normal">R</mi></mrow><annotation encoding="application/x-tex">y = ℝ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68889em;vertical-align:0em;"></span><span class="mord amsrm">R</span></span></span></span>．</p>
<p>输入空间<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>和输出空间<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span>构成了一个<strong>样本空间</strong>．对于样本空间中的样本<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo><mi>𝒙</mi><mo separator="true">,</mo><mi>𝑦</mi><mo stretchy="false">)</mo><mo>∈</mo><mi>X</mi><mo>×</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">(𝒙, 𝑦) ∈ X × Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span></span></span>，假定<strong>𝒙 和𝑦 之间的关系</strong>可以通过一个未知的<strong>真实映射函数</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><mi>g</mi><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y =g(𝒙)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose">)</span></span></span></span> 或真实条件概率分布<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>𝑝</mi><mi>r</mi></msub><mo stretchy="false">(</mo><mi>𝑦</mi><mi mathvariant="normal">∣</mi><mi>𝒙</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">𝑝_r(𝑦|𝒙)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose">)</span></span></span></span>来描述．机器学习的目标是<strong>找到一个模型来近似</strong>真实映射函数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>g</mi><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">g(𝒙)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose">)</span></span></span></span> 或真实条件概率分布<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>𝑝</mi><mi>r</mi></msub><mo stretchy="false">(</mo><mi>𝑦</mi><mi mathvariant="normal">∣</mi><mi>𝒙</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">𝑝_r(𝑦|𝒙)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose">)</span></span></span></span>．</p>
<p>通常根据经验来假设一个函数集合<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi></mrow><annotation encoding="application/x-tex">F</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span></span></span></span>，称为假设空间（Hypothesis Space），然后通过观测其在训练集<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span></span></span></span>上的特性，从中选择一个理想的假设（Hypothesis）<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>f</mi><mi mathvariant="normal">∗</mi></msup><mo>∈</mo><mi>F</mi></mrow><annotation encoding="application/x-tex">f^∗ ∈ F</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span></span></span></span>．</p>
<p>假设空间<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi></mrow><annotation encoding="application/x-tex">F</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span></span></span></span>通常为一个参数化的函数族</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>F</mi><mo>=</mo><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo><mi mathvariant="normal">∣</mi><mi>θ</mi><mo>∈</mo><msup><mi mathvariant="normal">R</mi><mi>𝐷</mi></msup></mrow></mrow><annotation encoding="application/x-tex">F = {f(x; \theta)|\theta \in ℝ^𝐷}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1413309999999999em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord amsrm">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中<span class="katex-error" title="Error: Font metrics not found for font: .">f(𝒙;𝜃)</span> 是参数为<span class="katex-error" title="Error: Font metrics not found for font: .">𝜃</span>的函数，也称为模型（Model），<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝐷</mi></mrow><annotation encoding="application/x-tex">𝐷</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span></span></span></span>为参数的数量．</p>
<h5 id="2211-线性模型"><a class="markdownIt-Anchor" href="#2211-线性模型"></a> 2.2.1.1 线性模型</h5>
<p>线性模型的假设空间为一个<strong>参数化的线性函数族</strong>，即</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">𝑓(𝒙; 𝜃) = 𝒘^T𝒙 + 𝑏
</p>
<p>其中参数<span class="katex-error" title="Error: Font metrics not found for font: .">𝜃</span>包含了<strong>权重向量</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝒘</mi></mrow><annotation encoding="application/x-tex">𝒘</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.44444em;vertical-align:0em;"></span><span class="mord boldsymbol" style="margin-right:0.11111em;">w</span></span></span></span>和<strong>偏置</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">b</span></span></span></span>．</p>
<h5 id="2212-非线性模型"><a class="markdownIt-Anchor" href="#2212-非线性模型"></a> 2.2.1.2 非线性模型</h5>
<p>广义的非线性模型可以写为多个<strong>非线性基函数</strong>𝜙(𝒙) 的<strong>线性组合</strong></p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">f(𝒙;𝜃) = 𝒘^T𝜙(𝒙) + 𝑏
</p>
<p>其中<span class="katex-error" title="Error: Font metrics not found for font: .">𝜙(𝒙) = [𝜙_1(𝒙), 𝜙_2(𝒙), ⋯ , 𝜙_𝐾 (𝒙)]^T</span>为𝐾 个<strong>非线性基函数</strong>组成的<strong>向量</strong>，参数𝜃<br>
包含了<strong>权重向量</strong>𝒘 和<strong>偏置</strong>𝑏．</p>
<h4 id="222-学习准则"><a class="markdownIt-Anchor" href="#222-学习准则"></a> 2.2.2 学习准则</h4>
<p>一个<strong>好的模型</strong><span class="katex-error" title="Error: Font metrics not found for font: .">f(𝒙, 𝜃^∗)</span>应该<strong>在所有</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo><mi>𝒙</mi><mo separator="true">,</mo><mi>𝑦</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(𝒙, 𝑦)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> 的<strong>可能取值</strong>上都<strong>与真实映射函数</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑦</mi><mo>=</mo><mi>g</mi><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">𝑦 = g(𝒙)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose">)</span></span></span></span><strong>一致</strong>，即</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">|𝑓(𝒙, 𝜃^∗) − 𝑦| &lt; 𝜖, ∀(𝒙, 𝑦) ∈ X × Y
</p>
<p>或与真实条件概率分布<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>p</mi><mi>r</mi></msub><mo stretchy="false">(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_r(y|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>一致，即</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">|f_y(𝒙, 𝜃^∗) − 𝑝_𝑟(𝑦|𝒙)| &lt; 𝜖, ∀(𝒙, 𝑦) ∈ X × Y,
</p>
<p>其中**<span class="katex-error" title="Error: Font metrics not found for font: .">𝜖</span>是一个很小的正数**，<span class="katex-error" title="Error: Font metrics not found for font: .">𝑓_𝑦(𝒙, 𝜃∗)</span>为模型预测的条件概率分布中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑦</mi></mrow><annotation encoding="application/x-tex">𝑦</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span>对应的概率．</p>
<p>模型<span class="katex-error" title="Error: Font metrics not found for font: .">f(𝒙; 𝜃)</span> 的好坏可以通过<strong>期望风险（Expected Risk）</strong><span class="katex-error" title="Error: Font metrics not found for font: .">R(𝜃)</span> 来衡量，其定义为</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">R(𝜃) = 𝔼_{(𝒙,𝑦)∼𝑝𝑟(𝒙,𝑦)}[L(𝑦, 𝑓(𝒙; 𝜃))],
</p>
<p>其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>𝑝</mi><mi>𝑟</mi></msub><mo stretchy="false">(</mo><mi>𝒙</mi><mo separator="true">,</mo><mi>𝑦</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">𝑝_𝑟(𝒙, 𝑦)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> 为真实的数据分布，<span class="katex-error" title="Error: Font metrics not found for font: .">L(𝑦, 𝑓(𝒙; 𝜃))</span>为<strong>损失函数</strong>，用来量化两个变量之间的差异．(y为真实值，<span class="katex-error" title="Error: Font metrics not found for font: .">f(x,𝜃)</span>为预测值）</p>
<h5 id="2221-损失函数"><a class="markdownIt-Anchor" href="#2221-损失函数"></a> 2.2.2.1 损失函数</h5>
<p>损失函数是一个<strong>非负实数函数</strong>，用来<strong>量化</strong>模型<strong>预测</strong>和<strong>真实</strong>标签之间的<strong>差异</strong>．下面介绍几种常用的损失函数．</p>
<h6 id="0-1损失函数"><a class="markdownIt-Anchor" href="#0-1损失函数"></a> 0-1损失函数</h6>
<p>最直观的损失函数是<strong>模型</strong>在<strong>训练集上的错误率</strong>，即0-1 损失函数（0-1 Loss Function）</p>
<p><img src="https://i.loli.net/2020/09/10/bhSn164EtPdDgf5.png" alt=""></p>
<p>虽然0-1损失函数能够<strong>客观评价模型的好坏</strong>，但其缺点是<strong>数学性质不够好</strong>；不连续且导数为0，难以优化</p>
<h6 id="平方损失函数"><a class="markdownIt-Anchor" href="#平方损失函数"></a> 平方损失函数</h6>
<p>平方损失函数（Quadratic Loss Function）经常用在<strong>预测标签𝑦为实数值</strong>的任务中，定义为</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">L(𝑦, 𝑓(𝒙; 𝜃)) =\frac{1}{2}(𝑦 − 𝑓(𝒙; 𝜃))^2
</p>
<p>但一般<strong>不适合分类问题</strong></p>
<h6 id="交叉熵损失函数"><a class="markdownIt-Anchor" href="#交叉熵损失函数"></a> 交叉熵损失函数</h6>
<p>交叉熵损失函数（Cross-Entropy Loss Function）一般用于分类问题．假设样本的标签<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑦</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><mo>⋯</mo><mo separator="true">,</mo><mi>𝐶</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">𝑦 ∈ [1, ⋯ , 𝐶]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mclose">]</span></span></span></span> 为离散的类别，模型<span class="katex-error" title="Error: Font metrics not found for font: .">f(𝒙; 𝜃) ∈ [0, 1]^𝐶</span>的输出为类别标签的条件概率分布，即</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">p(y=c|x;𝜃) = f_c(x;𝜃)
</p>
<p>并满足</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">f_c(x;𝜃) ∈ [0, 1], \sum^{C}_{c=1}f_c(x;𝜃)=1
</p>
<p>我们可以用一个𝐶 维的<strong>one-hot 向量</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝒚</mi></mrow><annotation encoding="application/x-tex">𝒚</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.63888em;vertical-align:-0.19444em;"></span><span class="mord boldsymbol" style="margin-right:0.105em;">y</span></span></span></span> 来表示样本标签．假设样本的标签为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑘</mi></mrow><annotation encoding="application/x-tex">𝑘</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>，那么<strong>标签向量</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝒚</mi></mrow><annotation encoding="application/x-tex">𝒚</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.63888em;vertical-align:-0.19444em;"></span><span class="mord boldsymbol" style="margin-right:0.105em;">y</span></span></span></span> 只有<strong>第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑘</mi></mrow><annotation encoding="application/x-tex">𝑘</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>维的值为1，其余元素的值都为0．<strong>标签向量<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝒚</mi></mrow><annotation encoding="application/x-tex">𝒚</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.63888em;vertical-align:-0.19444em;"></span><span class="mord boldsymbol" style="margin-right:0.105em;">y</span></span></span></span>可以</strong>看作样本标签的真实条件概率分布</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>𝑝</mi><mi>𝑟</mi></msub><mo stretchy="false">(</mo><mi>𝒚</mi><mi mathvariant="normal">∣</mi><mi>𝒙</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">𝑝_𝑟(𝒚|𝒙)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.105em;">y</span><span class="mord">∣</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose">)</span></span></span></span>，即第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑐</mi></mrow><annotation encoding="application/x-tex">𝑐</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">c</span></span></span></span>维（记为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>𝑦</mi><mi>𝑐</mi></msub></mrow><annotation encoding="application/x-tex">𝑦_𝑐</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn><mo>≤</mo><mi>𝑐</mi><mo>≤</mo><mi>𝐶</mi></mrow><annotation encoding="application/x-tex">1 ≤ 𝑐 ≤ 𝐶</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.78041em;vertical-align:-0.13597em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mord mathdefault">c</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span></span></span></span>）是类别为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">c</span></span></span></span> 的真实条件概率．假设样本的类别为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑘</mi></mrow><annotation encoding="application/x-tex">𝑘</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>，那么<strong>它属于第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑘</mi></mrow><annotation encoding="application/x-tex">𝑘</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span></span></span></span>类的概率为1，属于其他类的概率为0</strong>．</p>
<p>对于两个<strong>概率分布</strong>，一般可以<strong>用交叉熵</strong>来衡量它们的差异．标签的<strong>真实分布</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝒚</mi></mrow><annotation encoding="application/x-tex">𝒚</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.63888em;vertical-align:-0.19444em;"></span><span class="mord boldsymbol" style="margin-right:0.105em;">y</span></span></span></span>和模型<strong>预测分布</strong><span class="katex-error" title="Error: Font metrics not found for font: .">f(𝒙; 𝜃)</span>之间的<strong>交叉熵</strong>为</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">L(𝒚, 𝑓(𝒙; 𝜃)) = −𝒚^Tlogf(𝒙; 𝜃) = −\sum^C_{c=1}y_c log𝑓_𝑐(𝒙; 𝜃).
</p>
<p>比如对于三分类问题，一个样本的标签向量为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝒚</mi><mo>=</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">𝒚 = [0, 0, 1]^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.63888em;vertical-align:-0.19444em;"></span><span class="mord boldsymbol" style="margin-right:0.105em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>，模型预测的标签分布为<span class="katex-error" title="Error: Font metrics not found for font: .">𝑓(𝒙; 𝜃) = [0.3, 0.3, 0.4]^T</span>，则它们的交叉熵为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">−</mi><mo stretchy="false">(</mo><mn>0</mn><mo>×</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mn>0.3</mn><mo stretchy="false">)</mo><mo>+</mo><mn>0</mn><mo>×</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mn>0.3</mn><mo stretchy="false">)</mo><mo>+</mo><mn>1</mn><mo>×</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mn>0.4</mn><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">−</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mn>0.4</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">−(0 × log(0.3) + 0 × log(0.3) + 1 × log(0.4)) = − log(0.4)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mopen">(</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord">0</span><span class="mord">.</span><span class="mord">3</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord">0</span><span class="mord">.</span><span class="mord">3</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord">0</span><span class="mord">.</span><span class="mord">4</span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord">0</span><span class="mord">.</span><span class="mord">4</span><span class="mclose">)</span></span></span></span>．</p>
<h6 id="hinge损失函数"><a class="markdownIt-Anchor" href="#hinge损失函数"></a> Hinge损失函数</h6>
<p>略</p>
<h5 id="2222-风险最小化准则"><a class="markdownIt-Anchor" href="#2222-风险最小化准则"></a> 2.2.2.2 风险最小化准则</h5>
<p>一个好的模型𝑓(𝒙; 𝜃) 应当有一个比较小的期望错误，但由于不知道真实的数据分布和映射函数，实际上无法计算其期望风险ℛ(𝜃)</p>
<p>给定一个训练集<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi><mo>=</mo><msubsup><mrow><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">(</mo><mi>𝑛</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>𝑦</mi><mo stretchy="false">(</mo><mi>𝑛</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>𝑁</mi></msubsup></mrow><annotation encoding="application/x-tex">D = {(𝒙(𝑛), 𝑦(𝑛))}^𝑁_{n=1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2809309999999998em;vertical-align:-0.29969999999999997em;"></span><span class="mord"><span class="mord"><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mclose">)</span><span class="mclose">)</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.4003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29969999999999997em;"><span></span></span></span></span></span></span></span></span></span>，我们可以计算的是经验风险（Empirical Risk），即在训练集上<br>
的平均损失：</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">R^{emp}_D(𝜃) = \frac{1}{N}\sum^{N}_{n=1}L(𝑦(𝑛), 𝑓(𝒙(𝑛); 𝜃))
</p>
<p>一个切实可行的学习准则是找到一组参数<span class="katex-error" title="Error: Font metrics not found for font: .">𝜃^∗</span> 使得经验风险最小，即</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">𝜃^∗ = arg_𝜃minR^{emp}_D(𝜃)
</p>
<p>这就是**经验风险最小化(Empirical Risk Minimization, ERM)**准则</p>
<p>根据<strong>大数定理</strong>可知，当<strong>训练集</strong>大小<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">∣</mi><mi>D</mi><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">|D|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="mord">∣</span></span></span></span> 趋向于<strong>无穷大</strong>时，<strong>经验风险就趋向于期望风险</strong>． 然而通常情况下，我们<strong>无法获取无限</strong>的训练样本，并且<strong>训练样本</strong>往往是<strong>真实数据的一个很小的子集</strong>或者包含一定的噪声数据，不能很好地反映全部数据的真实分布．<strong>经验风险最小化原则</strong>很容易<strong>导致</strong>模型在训练集上错误率很低，但是在未知数据上错误率很高．这就是所谓的<strong>过拟合</strong>（Overfitting）．</p>
<blockquote>
<p>定义2.1 – <strong>过拟合</strong>： 给定一个假设空间ℱ，一个假设𝑓 属于ℱ，如果存在其他的假设𝑓′ 也属于ℱ, 使得在训练集上𝑓 的损失比𝑓′ 的损失小，但在整个样本空间上𝑓′ 的损失比𝑓 的损失小，那么就说假设𝑓 过度拟合训练数据</p>
</blockquote>
<p><strong>过拟合</strong>问题往往是由于<strong>训练数据少</strong>和<strong>噪声</strong>以及<strong>模型能力强</strong>等原因造成的．为了<strong>解决过拟合</strong>问题， 一般在经验风险最小化的基础上再<strong>引入参数的正则化</strong>（Regularization）来限制模型能力，这就是**结构风险最小化（Structure Risk Minimization，SRM）**准则：</p>
<p><img src="https://i.loli.net/2020/09/10/F874opJIgihvNV2.png" alt=""></p>
<p>其中‖𝜃‖ 是<strong>ℓ2 范数</strong>的<strong>正则化项</strong>，用来<strong>减少参数空间</strong>，避免过拟合；<strong>𝜆</strong> 用来<strong>控制正则化的强度</strong>．</p>
<p>和过拟合相反的一个概念是欠拟合（Underfitting），即<strong>模型不能很好地拟合训练数据</strong>，在<strong>训练集</strong>上的<strong>错误率</strong>比较高．<strong>欠拟合</strong>一般是由于<strong>模型能力不足</strong>造成的．图2.3给出了欠拟合和过拟合的示例．</p>
<p><img src="https://i.loli.net/2020/09/10/slahkmPMzwZrx7W.png" alt=""></p>
<p>总之，机器学习中的学习准则并不仅仅是拟合训练集上的数据，同时也要使得<strong>泛化错误最低</strong>．给定一个训练集，机器学习的目标是从假设空间中找到一个泛化错误较低的“理想”模型，<strong>以便更好地对未知的样本进行预测，特别是不在训练集中出现的样本</strong>．因此，我们可以将机器学习看作一个<strong>从有限、高维、有噪声的数据上</strong>得到<strong>更一般性规律</strong>的<strong>泛化</strong>问题．</p>
<h4 id="223-优化算法"><a class="markdownIt-Anchor" href="#223-优化算法"></a> 2.2.3 优化算法</h4>
<p>如何找到最优的模型<span class="katex-error" title="Error: Font metrics not found for font: .">f(𝒙, 𝜃^∗)</span> 就成了一个**最优化（Optimization）**问题．机器学习的训练过程其实就是最优化问题的求解过程．</p>
<p>在机器学习中，优化又可以分为<strong>参数优化</strong>和<strong>超参数优化</strong>．模型<span class="katex-error" title="Error: Font metrics not found for font: .">f(𝒙; 𝜃)</span> 中的<span class="katex-error" title="Error: Font metrics not found for font: .">𝜃</span>称为模型的参数，<strong>可以通过优化算法进行学习</strong>．除了可学习的参数<span class="katex-error" title="Error: Font metrics not found for font: .">𝜃</span>之外，<strong>还有一类参数是用来定义模型结构或优化策略</strong>的，这类参数叫作<strong>超参数</strong>（Hyper-Parameter）．</p>
<p>常见的超参数包括：聚类算法中的类别个数、梯度下降法中的步长、正则化项的系数、神经网络的层数、支持向量机中的核函数等．</p>
<p><strong>超参数的选取</strong>一般都是<strong>组合优化</strong>问题，<strong>很难通过优化算法来自动学习</strong>．因此，超参数优化是机器学习的一个经验性很强的技术，通常是按照人的经验设定，或者通过搜索的方法对一组超参数组合进行不断试错调整．</p>
<h5 id="2231-梯度下降法"><a class="markdownIt-Anchor" href="#2231-梯度下降法"></a> 2.2.3.1 梯度下降法</h5>
<p>在机器学习中，最简单、常用的优化算法就是<strong>梯度下降法</strong>，即首先初始化参数<span class="katex-error" title="Error: Font metrics not found for font: .">𝜃_0</span>，然后<strong>按下面的迭代公式来计算训练集𝒟 上风险函数的最小值</strong>：</p>
<p><img src="https://i.loli.net/2020/09/10/B8F51CVfmjJZD9l.png" alt=""></p>
<p>其中<span class="katex-error" title="Error: Font metrics not found for font: .">𝜃_𝑡</span> 为第𝑡 次迭代时的参数值，𝛼 为<strong>搜索步长</strong>．在机器学习中，𝛼 一般称为<strong>学习率</strong>（Learning Rate）．</p>
<h5 id="2232-提前停止"><a class="markdownIt-Anchor" href="#2232-提前停止"></a> 2.2.3.2 提前停止</h5>
<p>针对梯度下降的优化算法，除了加正则化项之外，还可以通过<strong>提前停止</strong>来<strong>防止过拟合</strong>．</p>
<p>在梯度下降训练的过程中，由于过拟合的原因，在训练样本上收敛的参数，并不一定在测试集上最优．因此，除了训练集和测试集之外，有时也会使用一个验证集（Validation Set）.在<strong>每次迭代</strong>时，把<strong>新得到的模型</strong>𝑓(𝒙; 𝜃)<strong>在验证集上进行测试</strong>，并计算错误率．（Development Set）．<strong>如果</strong>在验证集上的<strong>错误率不再下降</strong>，就<strong>停止迭代</strong>．这种策略叫提前停止（Early Stop）</p>
<p><img src="https://i.loli.net/2020/09/10/ydDMrKphcGzWUHn.png" alt=""></p>
<h5 id="2233-随机梯度下降法"><a class="markdownIt-Anchor" href="#2233-随机梯度下降法"></a> 2.2.3.3 随机梯度下降法</h5>
<p>目标函数是整个训练集上的风险函数，这种方式称为批量梯度下降法（Batch Gradient Descent，BGD）．<strong>批量梯度下降法</strong>在每次迭代时需要计算每个样本上损失函数的梯度并求和．当训练集中的样本数量𝑁 很大时，<strong>空间复杂度比较高，每次迭代的计算开销也很大．</strong></p>
<p>为了减少每次迭代的计算复杂度，我们也可以<strong>在每次迭代时只采集一个样本</strong>，计算这个样本损失函数的梯度并更新参数，即<strong>随机梯度下降法</strong>（Stochastic Gradient Descent，SGD）．当经过足够次数的迭代时，随机梯度下降也可以收敛到局部最优解．</p>
<p><img src="https://i.loli.net/2020/09/10/d9y3htzu8BCwDgO.png" alt=""></p>
<p>随机梯度下降相当于在批量梯度下降的梯度上引入了随机噪声．<strong>在非凸优化问题中，随机梯度下降更容易逃离局</strong><br>
<strong>部最优点．</strong></p>
<h5 id="2234-小批量梯度下降法"><a class="markdownIt-Anchor" href="#2234-小批量梯度下降法"></a> 2.2.3.4 小批量梯度下降法</h5>
<p>随机梯度下降法的一个缺点是无法充分利用计算机的并行计算能力．<strong>小批量梯度下降法（Mini-Batch Gradient Descent）<strong>是批量梯度下降和随机梯度下降的</strong>折中</strong>．<strong>每次迭代时，我们随机选取一小部分训练样本来计算梯度并更新参数</strong>，这样既可以兼顾随机梯度下降法的优点，也可以提高训练效率．</p>
<p>小批量随机梯度下降法有<strong>收敛快</strong>、<strong>计算开销小</strong>的优点，因此逐渐成为大规模的机器学习中的主要优化算法</p>
<h3 id="23-机器学习的简单示例线性回归"><a class="markdownIt-Anchor" href="#23-机器学习的简单示例线性回归"></a> 2.3 机器学习的简单示例——线性回归</h3>
<p><strong>线性回归</strong>（Linear Regression）是一种对<strong>自变量</strong>和<strong>因变量</strong>之间关系进行<strong>建模</strong>的<strong>回归分析</strong>．自变量<strong>数量为1</strong> 时称为<strong>简单</strong>回归，自变量<strong>数量大于1</strong> 时称为<strong>多元</strong>回归．</p>
<p>从<strong>机器学习</strong>的角度来看，<strong>自变量</strong>就是样本的<strong>特征向量</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝒙</mi><mo>∈</mo><msup><mi mathvariant="normal">R</mi><mi>D</mi></msup></mrow><annotation encoding="application/x-tex">𝒙 ∈ ℝ^D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord amsrm">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span></span></span></span></span></span></span></span></span></span></span>（每一维对应一个自变量），<strong>因变量</strong>是<strong>标签𝑦</strong>，这里𝑦 ∈ ℝ 是<strong>连续值</strong>（实数或连续整数）．<strong>假设空间</strong>是一组参数化的<strong>线性</strong>函数</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑓</mi><mo stretchy="false">(</mo><mi>𝒙</mi><mo separator="true">;</mo><mi>𝒘</mi><mo separator="true">,</mo><mi>𝑏</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>𝒘</mi><mi>T</mi></msup><mi>𝒙</mi><mo>+</mo><mi>𝑏</mi></mrow><annotation encoding="application/x-tex">𝑓(𝒙; 𝒘, 𝑏) = 𝒘^T𝒙 + 𝑏
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord boldsymbol" style="margin-right:0.11111em;">w</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9746609999999999em;vertical-align:-0.08333em;"></span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.11111em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">b</span></span></span></span></span></p>
<p>为简单起见，我们将公式(2.30) 写为</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑓</mi><mo stretchy="false">(</mo><mi>𝒙</mi><mo separator="true">;</mo><mover accent="true"><mi>𝒘</mi><mo>^</mo></mover><mo stretchy="false">)</mo><mo>=</mo><mover accent="true"><mi>𝒘</mi><mo>^</mo></mover><mi>T</mi><mi>𝒙</mi></mrow><annotation encoding="application/x-tex">𝑓(𝒙;𝒘̂) = 𝒘̂T𝒙
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.70788em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord boldsymbol" style="margin-right:0.11111em;">w</span></span><span style="top:-3.01344em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;">^</span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.70788em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.70788em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord boldsymbol" style="margin-right:0.11111em;">w</span></span><span style="top:-3.01344em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;">^</span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mover accent="true"><mi>𝒘</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">𝒘̂</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.70788em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.70788em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord boldsymbol" style="margin-right:0.11111em;">w</span></span><span style="top:-3.01344em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;">^</span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>分别称为<strong>增广权重向量</strong>和<strong>增广特征向量</strong></p>
<h4 id="231-参数学习"><a class="markdownIt-Anchor" href="#231-参数学习"></a> 2.3.1 参数学习</h4>
<p>给定一组包含𝑁 个训练样本的训练集𝒟，我们希望能够<strong>学习</strong>一个<strong>最优</strong>的线性回归的模型<strong>参数</strong>𝒘．<br>
我们介绍四种不同的<strong>参数估计方法</strong>：<strong>经验风险最小化</strong>、<strong>结构风险最小化</strong>、<strong>最大似然估计</strong>、<strong>最大后验估计</strong>．</p>
<h5 id="2311-经验风险最小化"><a class="markdownIt-Anchor" href="#2311-经验风险最小化"></a> 2.3.1.1 经验风险最小化</h5>
<p>由于线性回归的<strong>标签𝑦</strong>和<strong>模型输出</strong>都为<strong>连续的实数值</strong>， 因此<strong>平方损失函数</strong>非常<strong>适合</strong>衡量真实标签和预测标签之间的差异．</p>
<p>根据<strong>经验风险最小化</strong>准则，训练集𝒟 上的<strong>经验风险</strong>定义为<strong>每个样本损失函数的和</strong></p>
<p><img src="/2020/10/15/神经网络与深度学习-2-机器学习概述/C:%5CUsers%5CMSI-NB%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200911154649100.png" alt="image-20200911154649100"></p>
<p>其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝒚</mi><mo>=</mo><mo stretchy="false">[</mo><mi>𝑦</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>⋯</mo><mo separator="true">,</mo><mi>𝑦</mi><mo stretchy="false">(</mo><mi>𝑁</mi><mo stretchy="false">)</mo><msup><mo stretchy="false">]</mo><mi>T</mi></msup><mo>∈</mo><msup><mi mathvariant="normal">R</mi><mi>𝑁</mi></msup></mrow><annotation encoding="application/x-tex">𝒚 = [𝑦(1), ⋯ , 𝑦(𝑁)]^T ∈ ℝ^𝑁</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.63888em;vertical-align:-0.19444em;"></span><span class="mord boldsymbol" style="margin-right:0.105em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mclose">)</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord amsrm">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span></span></span></span></span></span></span></span> 是由<strong>所有样本</strong>的真实<strong>标签</strong>组成的<strong>列向量</strong>，而 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑿</mi><mo>∈</mo><msup><mi mathvariant="normal">R</mi><mrow><mo stretchy="false">(</mo><mi>𝐷</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>×</mo><mi>𝑁</mi></mrow></msup></mrow><annotation encoding="application/x-tex">𝑿 ∈ ℝ^{(𝐷+1)×𝑁}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72521em;vertical-align:-0.0391em;"></span><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord amsrm">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span></span></span></span></span></span></span></span></span> 是由<strong>所有样本</strong>的<strong>输入特征</strong><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝒙</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>⋯</mo><mo separator="true">,</mo><mi>𝒙</mi><mo stretchy="false">(</mo><mi>𝑁</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">𝒙(1), ⋯ , 𝒙(𝑁)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span> 组成的<strong>矩阵</strong>：</p>
<p>风险函数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>R</mi><mo stretchy="false">(</mo><mi>𝒘</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R(𝒘)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.11111em;">w</span><span class="mclose">)</span></span></span></span> 是关于𝒘 的<strong>凸函数</strong>(<strong>二阶导数小于0</strong>)，其对𝒘的偏导数为</p>
<p><img src="/2020/10/15/神经网络与深度学习-2-机器学习概述/C:%5CUsers%5CMSI-NB%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200911155426506.png" alt="image-20200911155426506"></p>
<p>在<strong>最小二乘法</strong>中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑿</mi><msup><mi>𝑿</mi><mi>T</mi></msup><mo>∈</mo><msup><mi mathvariant="normal">R</mi><mrow><mo stretchy="false">(</mo><mi>D</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>×</mo><mo stretchy="false">(</mo><mi>D</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">𝑿𝑿^T ∈ ℝ^{(D+1)×(D+1)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.880431em;vertical-align:-0.0391em;"></span><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord amsrm">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span><span class="mbin mtight">×</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span> 必须存在<strong>逆矩阵</strong>，即<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑿</mi><msup><mi>𝑿</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">𝑿𝑿^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span> 是<strong>满秩</strong>的</p>
<p>一种常见的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑿</mi><msup><mi>𝑿</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">𝑿𝑿^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span> <strong>不可逆情况</strong>是<strong>样本数量</strong>𝑁 <strong>小</strong>于<strong>特征数量</strong>(𝐷 + 1)，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑿</mi><msup><mi>𝑿</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">𝑿𝑿^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>的秩为𝑁．这时会存在很多解𝒘∗，可以使得ℛ(𝒘∗) = 0．</p>
<p>当<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑿</mi><msup><mi>𝑿</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">𝑿𝑿^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span> <strong>不可逆</strong>时，可以通过下面两种方法来<strong>估计参数</strong>：</p>
<ol>
<li>先使用<strong>主成分分析</strong>等方法来<strong>预处理</strong>数据，消除不同特征之间的相关性，然后再使用最小二乘法来<br>
估计参数；</li>
<li>使用<strong>梯度下降法</strong>来<strong>估计</strong>参数．先初始化𝒘 = 0，然后进行迭代.利用<strong>梯度下降法</strong>来<strong>求解</strong>的方法也称为<strong>最小均方（Least</strong><br>
**Mean Squares，LMS）**算法</li>
</ol>
<h5 id="2312-结构风险最小化"><a class="markdownIt-Anchor" href="#2312-结构风险最小化"></a> 2.3.1.2 结构风险最小化</h5>
<p>即使<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑿</mi><msup><mi>𝑿</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">𝑿𝑿^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span> 可逆，如果特征之间有较大的<strong>多重共线性</strong>（Multicollinearity，共线性是指<strong>一个特征</strong>可以通过<strong>其他特征的线性组合</strong>来<strong>较准确地预测</strong>．），也会使得<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑿</mi><msup><mi>𝑿</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">𝑿𝑿^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span> 的逆在数值上无法准确计算．数据集𝑿 上一些小的扰动就会导致<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo><mi>𝑿</mi><msup><mi>𝑿</mi><mi>T</mi></msup><msup><mo stretchy="false">)</mo><mrow><mi mathvariant="normal">−</mi><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">(𝑿𝑿^T)^{−1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>发生大的改变，进而使得最小二乘法的计算变得很不稳定．岭回归（Ridge Regression）解决这个问题，给<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑿</mi><msup><mi>𝑿</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">𝑿𝑿^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>的<strong>对角线元素</strong>都<strong>加上</strong>一个<strong>常数𝜆</strong> 使得(𝑿𝑿T + 𝜆𝐼) <strong>满秩</strong>，即其行列式不为0．其中<strong>𝜆</strong> &gt; 0 为预先设置的<strong>超参数</strong>，<strong>𝐼</strong> 为<strong>单位矩阵</strong>．最优的参数𝒘∗ 为</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">𝒘∗ = (𝑿𝑿^T + 𝜆𝐼)^{−1}𝑿𝒚
</p>
<p>岭回归的解𝒘∗ 可以看作结构风险最小化准则下的最小二乘法估计，其<strong>目标函数</strong>（经验风险）可以写为</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">R(𝒘) = \frac12 ‖𝒚 − 𝑿^T𝒘‖^2 + \frac12𝜆‖𝒘‖2
</p>
<h5 id="2313-最大似然估计"><a class="markdownIt-Anchor" href="#2313-最大似然估计"></a> 2.3.1.3 最大似然估计</h5>
<p>机器学习任务可以分为两类： <strong>一类</strong>是样本的特征向量𝒙 和标签𝑦 之间存在未知的<strong>函数关系</strong>𝑦 = ℎ(𝒙)，<strong>另一类</strong>是<strong>条件概率</strong>𝑝(𝑦|𝒙) 服从某个未知<strong>分布</strong>．</p>
<p>假设标签𝑦 为一个随机变量，并由函数$f(𝒙; 𝒘) = 𝒘^T𝒙 $加上一个随机噪声𝜖决定，即</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">𝑦 = 𝑓(𝒙; 𝒘) + 𝜖 = 𝒘^T𝒙 + 𝜖
</p>
<p>其中<span class="katex-error" title="Error: Font metrics not found for font: .">𝜖</span>服从均值为0、方差为<span class="katex-error" title="Error: Font metrics not found for font: .">𝜎^2</span> 的高斯分布．这样，𝑦 服从均值为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>𝒘</mi><mi>T</mi></msup><mi>𝒙</mi></mrow><annotation encoding="application/x-tex">𝒘^T𝒙</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.11111em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span></span></span></span>、方差为<span class="katex-error" title="Error: Font metrics not found for font: .">𝜎^2</span>的高斯分布：</p>
<p><img src="/2020/10/15/神经网络与深度学习-2-机器学习概述/C:%5CUsers%5CMSI-NB%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200911161807338.png" alt="image-20200911161807338"></p>
<p>参数𝒘 在训练集𝒟 上的似然函数（Likelihood）为</p>
<p><img src="/2020/10/15/神经网络与深度学习-2-机器学习概述/C:%5CUsers%5CMSI-NB%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200911161941823.png" alt="image-20200911161941823"></p>
<p>其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝒚</mi><mo>=</mo><mo stretchy="false">[</mo><mi>𝑦</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>⋯</mo><mo separator="true">,</mo><mi>𝑦</mi><mo stretchy="false">(</mo><mi>𝑁</mi><mo stretchy="false">)</mo><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">𝒚 = [𝑦(1), ⋯ , 𝑦(𝑁)]^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.63888em;vertical-align:-0.19444em;"></span><span class="mord boldsymbol" style="margin-right:0.105em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mclose">)</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>为所有<strong>样本标签</strong>组成的<strong>向量</strong>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑿</mi><mo>=</mo><mo stretchy="false">[</mo><mi>𝒙</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>⋯</mo><mo separator="true">,</mo><mi>𝒙</mi><mo stretchy="false">(</mo><mi>𝑁</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">𝑿 = [𝒙(1), ⋯ , 𝒙(𝑁)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mclose">)</span><span class="mclose">]</span></span></span></span>为所有样本<strong>特征向量</strong>组成的<strong>矩阵</strong>．</p>
<p>似然函数是关于统计模型的参数的函数．似然𝑝(𝑥|𝑤) 和概率𝑝(𝑥|𝑤) 之间的区别在于：<strong>概率</strong>𝑝(𝑥|𝑤) 是描述<strong>固定参数𝑤</strong> 时<strong>随机</strong><br>
<strong>变量𝑥</strong> 的分布情况，而<strong>似然</strong>𝑝(𝑥|𝑤) 则是描述<strong>已知随机变量𝑥</strong> 时<strong>不同的参数𝑤 对其分布的影响</strong>．</p>
<p><strong>最大似然估计（Maximum Likelihood Estimation，MLE）<strong>是指找到</strong>一组参数𝒘</strong> 使得<strong>似然函数</strong>𝑝(𝒚|𝑿; 𝒘, 𝜎) 最<strong>大</strong>，等价于对数似然函数log 𝑝(𝒚|𝑿; 𝒘, 𝜎)最大．可得</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>𝒘</mi><mrow><mi>𝑀</mi><mi>𝐿</mi></mrow></msup><mo>=</mo><mo stretchy="false">(</mo><mi>𝑿</mi><msup><mi>𝑿</mi><mi>T</mi></msup><msup><mo stretchy="false">)</mo><mrow><mi mathvariant="normal">−</mi><mn>1</mn></mrow></msup><mi>𝑿</mi><mi>𝒚</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">𝒘^{𝑀𝐿} = (𝑿𝑿^T)^{−1}𝑿𝒚.
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8913309999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.11111em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">M</span><span class="mord mathdefault mtight">L</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1413309999999999em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.864108em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord boldsymbol" style="margin-right:0.15681em;">X</span><span class="mord boldsymbol" style="margin-right:0.105em;">y</span><span class="mord">.</span></span></span></span></span></p>
<p><strong>最大似然估计的解</strong>和<strong>最小二乘法的解</strong>相<strong>同</strong>．</p>
<h5 id="2314-最大后验估计"><a class="markdownIt-Anchor" href="#2314-最大后验估计"></a> 2.3.1.4 最大后验估计</h5>
<p><strong>最大似然估计</strong>的一个<strong>缺点</strong>是当训练数据比较少时会发生<strong>过拟合</strong>，估计的参数可能不准确．为了避免过拟合，我们可以给<strong>参数</strong>加上一些<strong>先验知识</strong>．</p>
<p>假设参数𝒘 为一个随机向量，并服从一个<strong>先验分布</strong>𝑝(𝒘; 𝜈)．为简单起见，一般令𝑝(𝒘; 𝜈) 为各向同性的高斯分布：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑝</mi><mo stretchy="false">(</mo><mi>𝒘</mi><mo separator="true">;</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><mi>N</mi><mo stretchy="false">(</mo><mi>𝒘</mi><mo separator="true">;</mo><mn>0</mn><mo separator="true">,</mo><msup><mi>v</mi><mn>2</mn></msup><mi>I</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">𝑝(𝒘; v) = N(𝒘; 0, v^2I)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.11111em;">w</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.11111em;">w</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mclose">)</span></span></span></span></span></p>
<p>根据贝叶斯公式，参数𝒘 的<strong>后验分布</strong>（Posterior Distribution）为</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">𝑝(𝒘|𝑿, 𝒚; 𝜈, 𝜎) = \frac{𝑝(𝒘, 𝒚|𝑿; 𝜈, 𝜎)}{Σ_𝒘 𝑝(𝒘, 𝒚|𝑿; 𝜈, 𝜎)} ∝ 𝑝(𝒚|𝑿, 𝒘; 𝜎)𝑝(𝒘; 𝜈),
</p>
<p>最大似然估计和贝叶斯估计可以分别看作<strong>频率学派</strong>和<strong>贝叶斯学派</strong>对需要估计的参数𝒘 的不同解释．当𝜈 → ∞ 时，先验分布𝑝(𝒘; 𝜈) 退化为均匀分布，称为无信息先验（Non-Informative Prior），最大后验估计退化为最大似然估计．</p>
<h3 id="24-偏差-方差分解"><a class="markdownIt-Anchor" href="#24-偏差-方差分解"></a> 2.4 偏差-方差分解</h3>
<p>我们经常会在模型的拟合能力和复杂度之间进行权衡．<strong>拟合能力强</strong>的模型一般<strong>复杂度</strong>会比较<strong>高</strong>，容易导致<strong>过拟合</strong>．相反，如果限制模型的复杂度，降低其拟合能力，又可能会导致欠拟合．因此，如何在<strong>模型</strong>的<strong>拟合能力</strong>和<strong>复杂度</strong>之间取得一个较好的<strong>平衡</strong>，对一个机器学习算法来讲十分重要．<strong>偏差-方差分解</strong>（Bias-Variance Decomposition）为我们提供了一个很好的分析和指导工具．</p>
<p>以回归问题为例，假设样本的真实分布为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>𝑝</mi><mi>𝑟</mi></msub><mo stretchy="false">(</mo><mi>𝒙</mi><mo separator="true">,</mo><mi>𝑦</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">𝑝_𝑟(𝒙, 𝑦)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>，并采用平方损失函数，模型𝑓(𝒙) 的期望错误为</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>R</mi><mo stretchy="false">(</mo><mi>f</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>𝔼</mi><mrow><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>∼</mo><mi>p</mi><mi>r</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi>y</mi><mi mathvariant="normal">−</mi><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">]</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">R(f) = 𝔼_{(x,y)∼pr(x,y)}[(y − f(x))^2].
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2193079999999998em;vertical-align:-0.3551999999999999em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mclose mtight">)</span><span class="mrel mtight">∼</span><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">−</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">]</span><span class="mord">.</span></span></span></span></span></p>
<p>这个公式的意思就是当<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>满足真实分布<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>𝑝</mi><mi>𝑟</mi></msub><mo stretchy="false">(</mo><mi>𝒙</mi><mo separator="true">,</mo><mi>𝑦</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">𝑝_𝑟(𝒙, 𝑦)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>时，模型<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>的期望错误</p>
<p>假设<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>f</mi><mi mathvariant="normal">∗</mi></msup><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f^∗(𝒙)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose">)</span></span></span></span> 为使用平方损失作为优化目标的<strong>最优模型</strong>，其损失为</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">𝜖 = 𝔼_{(x,y)∼𝑝_𝑟(x,y)}[(y − f^∗(x))^2].
</p>
<p><strong>损失𝜖</strong> 通常是由于<strong>样本分布</strong>以及<strong>噪声</strong>引起的，<strong>无法</strong>通过<strong>优化</strong>模型来减少．</p>
<p>那么一般模型的期望错误可以分解为</p>
<p><img src="https://i.loli.net/2020/09/12/akQsyMEFw1THSh7.png" alt=""></p>
<p>其中<strong>第一项</strong>是<strong>当前模型和最优模型</strong>之间的<strong>差距</strong>，是机器学习算法<strong>可以优化</strong>的真实<strong>目标</strong>．第二项无法优化</p>
<p>在实际训练一个模型𝑓(𝒙) 时，<strong>训练集𝒟</strong> 是从真实分布<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>𝑝</mi><mi>𝑟</mi></msub><mo stretchy="false">(</mo><mi>𝒙</mi><mo separator="true">,</mo><mi>𝑦</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">𝑝_𝑟(𝒙, 𝑦)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> 上独立同分布地<strong>采样</strong>出来的<strong>有限样本集合</strong>．不同的训练集会得到不同的模型．令<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>f</mi><mi>D</mi></msub><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f_D(𝒙)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose">)</span></span></span></span> 表示在训练集𝒟 上学习到的模型，一个<strong>机器学习算法</strong>（包括模型以及优化算法）的<strong>能力</strong>可以用<strong>不同训练集</strong>上的模型的<strong>平均性能</strong>来评价．</p>
<p>对于单个样本𝒙，不同训练集𝒟 得到模型<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>f</mi><mi>D</mi></msub><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f_D(𝒙)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose">)</span></span></span></span> 和最优模型<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>𝑓</mi><mo>∗</mo></msup><mo stretchy="false">(</mo><mi>𝒙</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">𝑓^*(𝒙)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="mclose">)</span></span></span></span> 的期望差距为</p>
<p><img src="https://i.loli.net/2020/09/12/akQsyMEFw1THSh7.png" alt=""></p>
<p>也就是把<strong>期望差距拆分</strong>成两部分，一部分是<strong>偏差</strong>，是指一个模型在<strong>不同训练集</strong>上的<strong>平均性能</strong>和<strong>最优模型</strong>的差异，可以用来<strong>衡量</strong>一个模型的<strong>拟合能力</strong>．第二项是<strong>方差</strong>（Variance），是指一个模型在<strong>不同训练集上的差异</strong>，可以用来<strong>衡量</strong>一个模型是否容易<strong>过拟合</strong>．</p>
<p><img src="/2020/10/15/神经网络与深度学习-2-机器学习概述/C:%5CUsers%5CMSI-NB%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200912093218749.png" alt="image-20200912093218749"></p>
<p><strong>最小化期望错误</strong>等价于<strong>最小化偏差和方差之和</strong>．</p>
<p>图2.6给出了机器学习模型的四种偏差和方差组合情况．每个图的<strong>中心点</strong>为<strong>最优模型</strong>𝑓∗(𝒙)，<strong>蓝点</strong>为<strong>不同训练集</strong>𝐷 上得到的<strong>模型</strong>𝑓𝒟 (𝒙)．图2.6a给出了一种理想情况，<strong>方差</strong>和<strong>偏差</strong>都比较<strong>低</strong>．图2.6b为<strong>高偏差低方差</strong>的情况，表示模型的<strong>泛化</strong>能力很<strong>好</strong>，但<strong>拟合</strong>能力<strong>不足</strong>．图2.6c为<strong>低偏差高方差</strong>的情况，表示模型的<strong>拟合</strong>能力很<strong>好</strong>，但<strong>泛化</strong>能力比较<strong>差</strong>．当训练数据比较少时会导致过拟合．图2.6d为高偏差高方差的情况，是一种最差的情况．</p>
<p><img src="https://i.loli.net/2020/09/12/PAJQW9vzeqaM43y.png" alt=""></p>
<p><strong>方差</strong>一般会随着<strong>训练样本</strong>的<strong>增加</strong>而<strong>减少</strong>．当样本比较多时，方差比较少，这时可以选择能力强的模型来减少偏差．</p>
<p>随着<strong>模型复杂度</strong>的<strong>增加</strong>，模型的<strong>拟合能力变强</strong>，<strong>偏差减少</strong>而<strong>方差增大</strong>，从而导致<strong>过拟合</strong>．以结构风险最小化为例，我们可以<strong>调整正则化系数𝜆</strong> 来<strong>控制</strong>模型的<strong>复杂度</strong>． 当𝜆 变大时，模型复杂度会降低，可以有效地<strong>减少方差</strong>，避免<strong>过拟合</strong>，但<strong>偏差</strong>会<strong>上升</strong>．</p>
<p>图2.7给出了机器学习模型的<strong>期望错误</strong>、<strong>偏差</strong>和<strong>方差</strong>随<strong>复杂度</strong>的<strong>变化</strong>情况，其中红色虚线表示最优模型．最优模型并不一定是偏差曲线和方差曲线的交点．</p>
<p><img src="https://i.loli.net/2020/09/12/ix79b5HkJPw1K8o.png" alt=""></p>
<p>一般来说，当一个模型在<strong>训练集</strong>上的<strong>错误率</strong>比较<strong>高</strong>时，说明模型的<strong>拟合能力不够</strong>，<strong>偏差</strong>比较<strong>高</strong>．这种情况可以通过<strong>增加数据特征</strong>、<strong>提高模型复杂度</strong>、<strong>减小正则化系数</strong>等操作来改进．当模型在<strong>训练集</strong>上的<strong>错误率</strong>比较<strong>低</strong>，但<strong>验证集</strong>上的<strong>错误率</strong>比较<strong>高</strong>时，说明模型<strong>过拟合</strong>，<strong>方差</strong>比较<strong>高</strong>．这种情况可以通过<strong>降低模型复杂度</strong>、<strong>加大正则化系数</strong>、<strong>引入先验</strong>等方法来缓解．此外，还有一种有效降低方差的方法为集成模型，即通过多个高方差模型的平均来降低方差．</p>
<h3 id="25-机器学习算法的类型"><a class="markdownIt-Anchor" href="#25-机器学习算法的类型"></a> 2.5 机器学习算法的类型</h3>
<p>我们会按照训练样本提供的信息以及反馈方式的不同，将机器学习算法分为以下几类：</p>
<h4 id="251-监督学习"><a class="markdownIt-Anchor" href="#251-监督学习"></a> 2.5.1 监督学习</h4>
<p>如果机器学习的目标是<strong>建模</strong>样本的<strong>特征𝒙</strong> 和<strong>标签𝑦</strong> 之间的<strong>关系</strong>：𝑦 =𝑓(𝒙; 𝜃) 或𝑝(𝑦|𝒙; 𝜃)，并且训练集中每个样本都有标签，那么这类机器学习称为<strong>监督学习</strong>（Supervised Learning）．根据<strong>标签类型</strong>的不同，监督学习又可以分为<strong>回归问题</strong>、<strong>分类问题</strong>和<strong>结构化学习</strong>问题．</p>
<ol>
<li><strong>回归</strong>（Regression）问题中的<strong>标签𝑦 是连续值</strong>（实数或连续整数），𝑓(𝒙; 𝜃) 的输出也是连续值．</li>
<li><strong>分类</strong>（Classification）问题中的<strong>标签𝑦 是离散</strong>的类别（符号）．在分类问题中，学习到的模型也称为分类器（Classifier）．分类问题根据其类别数量又可分为二分类（Binary Classification）和多分类（Multi-class Classification）问题．</li>
<li><strong>结构化学习</strong>（Structured Learning）问题是一种特殊的分类问题．在结构化学习中，<strong>标签𝒚</strong> 通常是<strong>结构化的对象</strong>，比如<strong>序列</strong>、<strong>树</strong>或<strong>图</strong>等．由于结构化学习的输出空间比较大，因此我们一般定义一个<strong>联合特征空间</strong>，将𝒙, 𝒚 映射为该空间中的<strong>联合特征向量</strong>𝜙(𝒙, 𝒚)，预测模型可以写为</li>
</ol>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">𝒚 = argmax_{𝒚∈Gen(𝒙)}𝑓(𝜙(𝒙, 𝒚); 𝜃)
</p>
<p>其中Gen(𝒙) 表示输入𝒙 的所有可能的输出目标集合．计算argmax 的过程也称为<strong>解码</strong>（Decoding）过程，一般通过动态规划的方法来计算．</p>
<h4 id="252-无监督学习"><a class="markdownIt-Anchor" href="#252-无监督学习"></a> 2.5.2 无监督学习</h4>
<p>无监督学习（Unsupervised Learning，UL）是指<strong>从不包含目标标签的训练样本</strong>中自动学习到一些有价值的信息．典型的无监督学习问题有<strong>聚类</strong>、<strong>密度估计</strong>、<strong>特征学习</strong>、<strong>降维</strong>等．</p>
<h4 id="253-强化学习"><a class="markdownIt-Anchor" href="#253-强化学习"></a> 2.5.3 强化学习</h4>
<p>强化学习（Reinforcement Learning，RL）是一类通过交互来学习的机器学习算法．在强化学习中，智能体根据环境的状态做出一个动作，并得到即时或延时的奖励．智能体在和环境的交互中不断学习并调整策略，以取得最大化的期望总回报．</p>
<p><img src="https://i.loli.net/2020/09/12/OGKcky8ItA1QCvd.png" alt=""></p>
<h3 id="26-数据的特征表示"><a class="markdownIt-Anchor" href="#26-数据的特征表示"></a> 2.6 数据的特征表示</h3>
<p>在实际应用中，数据的类型多种多样，比如文本、音频、图像、视频等．不同类型的数据，其<strong>原始特征</strong>（Raw Feature）的<strong>空间</strong>也<strong>不相同</strong>．因此在机器学习之前我们需要将这些不同类型的数据<strong>转换为向量表示</strong>．</p>
<h4 id="261-图像特征"><a class="markdownIt-Anchor" href="#261-图像特征"></a> 2.6.1 图像特征</h4>
<p>略</p>
<h4 id="262-文本特征"><a class="markdownIt-Anchor" href="#262-文本特征"></a> 2.6.2 文本特征</h4>
<p>在文本情感分类任务中，样本𝑥 为自然语言文本，类别<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑦</mi><mo>∈</mo><mrow><mo>+</mo><mn>1</mn><mo separator="true">,</mo><mi mathvariant="normal">−</mi><mn>1</mn></mrow></mrow><annotation encoding="application/x-tex">𝑦 ∈ {+1, −1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335400000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord">+</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">−</span><span class="mord">1</span></span></span></span></span>分别表示正面或负面的评价．为了将样本𝑥 从文本形式转为向量形式，一种简单的方式是使用<strong>词袋</strong>（Bag-of-Words，BoW）模型． 词袋模型在信息检索中也叫作向量空间模型（Vector Space Model，VSM）．<strong>假设训练集合</strong>中的<strong>词</strong>都来自一个<strong>词表𝒱</strong>，大小为|𝒱|，则每个样本可以表示为一个|𝒱| 维的向量𝒙 ∈ ℝ|𝒱|．向量𝒙 中第𝑖 维的值表示词表中的第𝑖 个词是否在𝑥 中出现．如果出现，值为1，否则为0．</p>
<p>比如两个文本“我喜欢读书”和“我讨厌读书”中共有“我”“喜欢”“讨厌”“读书”四个词，它们的BoW 表示分别为</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>𝒙</mi><mn>1</mn></msub><mo>=</mo><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><msup><mo stretchy="false">]</mo><mi>T</mi></msup><mo separator="true">,</mo><msub><mi>𝒙</mi><mn>2</mn></msub><mo>=</mo><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><msup><mo stretchy="false">]</mo><mi>T</mi></msup><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">𝒙_1 = [1, 1, 0, 1 ]^T,
𝒙_2 = [1, 0, 1, 1 ]^T.
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.59444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.12583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1413309999999999em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.12583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1413309999999999em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord">.</span></span></span></span></span></p>
<p><strong>词袋模型</strong>将文本看作词的集合，<strong>不考虑词序信息</strong>，不能精确地表示文本信息．一种改进方式是使用<strong>N 元特征</strong>（N-Gram Feature），即<strong>每𝑁 个连续词构成一个基本单元</strong>，然后<strong>再用词袋模型</strong>进行表示．</p>
<p>以最简单的二元特征（即两个词的组合特征）为例，上面的两个文本中共有“$ 我”“我喜欢”“我讨厌”“喜欢读书”“讨<br>
厌读书”“读书#”六个特征单元，它们的二元特征BoW 表示分别为</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>𝒙</mi><mn>1</mn></msub><mo>=</mo><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><msup><mo stretchy="false">]</mo><mi>T</mi></msup><mo separator="true">,</mo><msub><mi>𝒙</mi><mn>2</mn></msub><mo>=</mo><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><msup><mo stretchy="false">]</mo><mi>T</mi></msup><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">𝒙_1 = [1, 1, 0, 1, 0, 1]^T,
𝒙_2 = [1, 0, 1, 0, 1, 1]^T.
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.59444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.12583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1413309999999999em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord boldsymbol" style="margin-right:0.12583em;">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.12583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1413309999999999em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord">.</span></span></span></span></span></p>
<h4 id="263表示学习"><a class="markdownIt-Anchor" href="#263表示学习"></a> 2.6.3表示学习</h4>
<p>如果直接用数据的原始特征来进行预测，对机器学习模型的能力要求比较高．这些<strong>原始特征</strong>可能存在以下几种<strong>不足</strong>：</p>
<ol>
<li>特征比较<strong>单一</strong>，需要进行（非线性的）<strong>组合</strong>才能<strong>发挥其作用</strong>；</li>
<li>特征之间<strong>冗余度</strong>比较高；</li>
<li><strong>并不是所有的特征</strong>都对预测<strong>有用</strong>；</li>
<li>很多特征通常是<strong>易变</strong>的；</li>
<li>特征中往往存在一些<strong>噪声</strong>．</li>
</ol>
<p>为了提高机器学习算法的能力，我们需要抽取有效、稳定的特征．传统的特征提取是通过人工方式进行的，需要大量的人工和专家知识．一个成功的机器学习系统通常需要尝试大量的特征，称为特征工程（Feature Engineering）．	因此，如何让<strong>机器自动</strong>地<strong>学习</strong>出<strong>有效的特征</strong>也成为机器学习中的一项重要研究内容，称为<strong>特征学习</strong>（Feature Learning），也叫<strong>表示学习</strong>（Representation Learning）．<br>
<strong>特征学习</strong>在一定程度上也可以<strong>减少模型复杂性</strong>、<strong>缩短训练时间</strong>、<strong>提高模型泛化能力</strong>、<strong>避免过拟合</strong>等．</p>
<h4 id="264-传统的特征学习"><a class="markdownIt-Anchor" href="#264-传统的特征学习"></a> 2.6.4 传统的特征学习</h4>
<p><strong>传统的特征学习</strong>一般是通过<strong>人为</strong>地设计一些<strong>准则</strong>，然后根据这些准则来<strong>选取有效的特征</strong>，具体又可以分为两种：<strong>特征选择</strong>和<strong>特征抽取</strong>．</p>
<h5 id="2641-特征选择"><a class="markdownIt-Anchor" href="#2641-特征选择"></a> 2.6.4.1 特征选择</h5>
<p><strong>特征选择</strong>（Feature Selection）是<strong>选取原始特征集合</strong>的一个有效<strong>子集</strong>，使得<strong>基于这个特征子集</strong>训练出来的模型<strong>准确率最高</strong>．简单地说，特征选择就是<strong>保留有用</strong>特征，<strong>移除</strong>冗余或<strong>无关</strong>的特征．</p>
<h5 id="2642-特征抽取"><a class="markdownIt-Anchor" href="#2642-特征抽取"></a> 2.6.4.2 特征抽取</h5>
<p><strong>特征抽取</strong>（Feature Extraction）是<strong>构造</strong>一个<strong>新的特征空间</strong>，并将原始特征投影在新的空间中得到新的表示．</p>
<p><strong>特征抽取</strong>又可以分为<strong>监督</strong>和<strong>无监督</strong>的方法．监督的特征学习的目标是抽取对一个特定的预测任务最有用的特征，比如线性判别分析（Linear Discriminant Analysis，LDA）．而无监督的特征学习和具体任务无关，其目标通常是减少冗余信息和噪声，比如主成分分析（Principal Component Analysis，PCA）和自编码器（Auto-Encoder，AE）</p>
<p>特征选择和特征抽取的<strong>优点</strong>是可以用<strong>较少的特征</strong>来<strong>表示原始特征中的大部分相关信息</strong>，去掉<strong>噪声</strong>信息，并进而提高计算效率和减小维度灾难（Curse of Dimensionality）经过特征选择或特征抽取后，特征的数量一般会减少，因此特征选择和特征抽取，也经常称为<strong>维数约减</strong>或<strong>降维</strong>（Dimension Reduction）．</p>
<h4 id="265-深度学习方法"><a class="markdownIt-Anchor" href="#265-深度学习方法"></a> 2.6.5 深度学习方法</h4>
<p>传统的<strong>特征抽取</strong>一般是和<strong>预测</strong>模型的学习<strong>分离</strong>的．我们会先通过主成分分析或线性判别分析等方法抽取出有效的特征，然后再基于这些特征来训练一个具体的机器学习模型．</p>
<p>如果我们<strong>将</strong>特征的<strong>表示学习</strong>和机器学习的<strong>预测学习</strong>有机地<strong>统一到一个模型中</strong>，建立一个端到端的学习算法，就可以有效地避免它们之间准则的不一致性．这种表示学习方法称为<strong>深度学习</strong>（Deep Learning，DL）</p>
<h3 id="27-评判标准"><a class="markdownIt-Anchor" href="#27-评判标准"></a> 2.7 评判标准</h3>
<p>为了<strong>衡量</strong>一个<strong>机器学习模型的好坏</strong>，需要给定一个<strong>测试集</strong>，用模型对测试集中的每一个样本进行预测，并根据预测结果计算评价分数．</p>
<p>对于分类问题，常见的评价标准有<strong>准确率</strong>、<strong>精确率</strong>、<strong>召回率</strong>和<strong>F 值</strong>等．</p>
<p>给定测试集𝒯 = {(𝒙(1), 𝑦(1)), ⋯ , (𝒙(𝑁), 𝑦(𝑁))}，假设标签𝑦(𝑛) ∈ {1, ⋯ , 𝐶}，用学习好的模型𝑓(𝒙; 𝜃∗)对测试集中的每一个样本进行预测，结果为{𝑦(̂ 1),⋯, 𝑦(̂ 𝑁)}．</p>
<h4 id="271-准确率"><a class="markdownIt-Anchor" href="#271-准确率"></a> 2.7.1 准确率</h4>
<p>最常用的评价指标为<strong>准确率</strong>（Accuracy）</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>I</mi><mo stretchy="false">(</mo><mi>𝑦</mi><mo stretchy="false">(</mo><mi>𝑛</mi><mo stretchy="false">)</mo><mo>=</mo><mi>𝑦</mi><mover accent="true"><mo stretchy="false">(</mo><mo>^</mo></mover><mi>𝑛</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">A =\frac1N\sum^N_{n=1}I(𝑦(𝑛) = 𝑦(̂ 𝑛)),
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.0954490000000003em;vertical-align:-1.267113em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord">1</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.882887em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.267113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.26344em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01344em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mopen">(</span></span><span style="top:-3.319em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.25em;"><span></span></span></span></span></span><span class="mord mathdefault">n</span><span class="mclose">)</span><span class="mclose">)</span><span class="mpunct">,</span></span></span></span></span></p>
<h4 id="272-错误率"><a class="markdownIt-Anchor" href="#272-错误率"></a> 2.7.2 错误率</h4>
<p>和准确率相对应的就是<strong>错误率</strong>（Error Rate）：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="script">E</mi><mo>=</mo><mn>1</mn><mi mathvariant="normal">−</mi><mi>A</mi><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>𝑛</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>I</mi><mo stretchy="false">(</mo><mi>𝑦</mi><mo stretchy="false">(</mo><mi>𝑛</mi><mo stretchy="false">)</mo><mi mathvariant="normal">≠</mi><mi>𝑦</mi><mover accent="true"><mo stretchy="false">(</mo><mo>^</mo></mover><mi>𝑛</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">ℰ = 1 − A = \frac 1 N \sum ^N _{𝑛=1}I(𝑦(𝑛) ≠ 𝑦(̂ 𝑛)).
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7em;vertical-align:0em;"></span><span class="mord"><span class="mord mathscr" style="margin-right:0.18583em;">E</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord">1</span><span class="mord">−</span><span class="mord mathdefault">A</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.0954490000000003em;vertical-align:-1.267113em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord">1</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.882887em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.267113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.26344em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01344em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mopen">(</span></span><span style="top:-3.319em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.25em;"><span></span></span></span></span></span><span class="mord mathdefault">n</span><span class="mclose">)</span><span class="mclose">)</span><span class="mord">.</span></span></span></span></span></p>
<h4 id="273-精确率和召回率"><a class="markdownIt-Anchor" href="#273-精确率和召回率"></a> 2.7.3 精确率和召回率</h4>
<p><strong>准确率</strong>是<strong>所有类别</strong>整体性能的平均，如果希望对<strong>每个类</strong>都进行<strong>性能估计</strong>，就需要计算<strong>精确率</strong>（Precision）和<strong>召回率</strong>（Recall）</p>
<p>对于类别𝑐 来说，模型在测试集上的结果可以分为以下四种情况：</p>
<ol>
<li><strong>真正例</strong>（True Positive，TP）：一个样本的<strong>真实类别为𝑐</strong> 并且模型<strong>正确地预测为类别𝑐</strong>．这类样本数量记为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝑇</mi><msub><mi>𝑃</mi><mi>𝑐</mi></msub><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>𝑛</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mi>I</mi><mo stretchy="false">(</mo><mi>𝑦</mi><mo stretchy="false">(</mo><mi>𝑛</mi><mo stretchy="false">)</mo><mo>=</mo><mi>𝑦</mi><mover accent="true"><mo stretchy="false">(</mo><mo>^</mo></mover><mi>𝑛</mi><mo stretchy="false">)</mo><mo>=</mo><mi>𝑐</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">𝑇𝑃_𝑐 =
\sum^N_{𝑛=1}I(𝑦(𝑛) = 𝑦(̂ 𝑛) = 𝑐)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2809409999999999em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.26344em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01344em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mopen">(</span></span><span style="top:-3.319em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.25em;"><span></span></span></span></span></span><span class="mord mathdefault">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">c</span><span class="mclose">)</span></span></span></span></li>
<li><strong>假负例</strong>（False Negative，FN）：一个样本的<strong>真实类别为𝑐</strong>，模型<strong>错误地预测为其他类</strong>．这类样本数量记为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝐹</mi><msub><mi>𝑁</mi><mi>𝑐</mi></msub><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>𝑛</mi><mo>=</mo><mn>1</mn></mrow><mi>𝑁</mi></msubsup><mi>I</mi><mo stretchy="false">(</mo><mi>𝑦</mi><mo stretchy="false">(</mo><mi>𝑛</mi><mo stretchy="false">)</mo><mo>=</mo><mi>𝑐</mi><mo>∧</mo><mi>𝑦</mi><mover accent="true"><mo stretchy="false">(</mo><mo>^</mo></mover><mi>𝑛</mi><mo stretchy="false">)</mo><mi mathvariant="normal">≠</mi><mi>𝑐</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">𝐹𝑁_𝑐 = \sum ^𝑁_{𝑛=1}I(𝑦(𝑛) = 𝑐 ∧ 𝑦(̂ 𝑛) ≠ 𝑐)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2809409999999999em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.55556em;vertical-align:0em;"></span><span class="mord mathdefault">c</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∧</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.26344em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01344em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mopen">(</span></span><span style="top:-3.319em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.25em;"><span></span></span></span></span></span><span class="mord mathdefault">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">c</span><span class="mclose">)</span></span></span></span></li>
<li><strong>假正例</strong>（False Positive，FP）：一个样本的<strong>真实类别</strong>为<strong>其他类</strong>，模型<strong>错误地预测</strong>为类别<strong>𝑐</strong>．这类样本数量记为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>𝐹</mi><msub><mi>𝑃</mi><mi>𝑐</mi></msub><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>𝑛</mi><mo>=</mo><mn>1</mn></mrow><mi>𝑁</mi></msubsup><mi>I</mi><mo stretchy="false">(</mo><mi>𝑦</mi><mo stretchy="false">(</mo><mi>𝑛</mi><mo stretchy="false">)</mo><mi mathvariant="normal">≠</mi><mi>𝑐</mi><mo>∧</mo><mi>𝑦</mi><mover accent="true"><mo stretchy="false">(</mo><mo>^</mo></mover><mi>𝑛</mi><mo stretchy="false">)</mo><mo>=</mo><mi>𝑐</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">𝐹𝑃_𝑐 = \sum^𝑁_{𝑛=1}I(𝑦(𝑛) ≠ 𝑐 ∧ 𝑦(̂ 𝑛) = 𝑐)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2809409999999999em;vertical-align:-0.29971000000000003em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.981231em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.55556em;vertical-align:0em;"></span><span class="mord mathdefault">c</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∧</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.26344em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01344em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mopen">(</span></span><span style="top:-3.319em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.25em;"><span></span></span></span></span></span><span class="mord mathdefault">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">c</span><span class="mclose">)</span></span></span></span></li>
<li><strong>真负例</strong>（True Negative，TN）：一个样本的<strong>真实类别</strong>为<strong>其他类</strong>，模型也<strong>预测</strong>为<strong>其他类</strong>．这类样本数量记为𝑇𝑁𝑐．对于类别𝑐 来说，这种情况一般不需要关注．</li>
</ol>
<p>这四种情况可以用下表表示</p>
<p><img src="https://i.loli.net/2020/09/12/kXP5zW2icsgIOma.png" alt=""></p>
<p><strong>精确率</strong>（Precision），也叫<strong>精度</strong>或<strong>查准率</strong>，类别𝑐 的查准率是<strong>所有预测为类别𝑐</strong> 的样本中<strong>预测正确</strong>的比例：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>p</mi><mi>𝑐</mi></msub><mo>=</mo><mfrac><mrow><mi>𝑇</mi><msub><mi>𝑃</mi><mi>𝑐</mi></msub></mrow><mrow><mi>𝑇</mi><msub><mi>𝑃</mi><mi>𝑐</mi></msub><mo>+</mo><mi>𝐹</mi><msub><mi>𝑃</mi><mi>𝑐</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">p_𝑐 = \frac {𝑇𝑃_𝑐} {𝑇𝑃_𝑐 + 𝐹𝑃_𝑐}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.19633em;vertical-align:-0.8360000000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.3139999999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8360000000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p><strong>召回率</strong>（Recall），也叫<strong>查全率</strong>，类别𝑐 的查全率是所有<strong>真实标签</strong>为<strong>类别𝑐</strong> 的样本中<strong>预测正确</strong>的比例：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>R</mi><mi>c</mi></msub><mo>=</mo><mfrac><mrow><mi>T</mi><msub><mi>P</mi><mi>c</mi></msub></mrow><mrow><mi>T</mi><msub><mi>P</mi><mi>c</mi></msub><mo>+</mo><mi>F</mi><msub><mi>N</mi><mi>c</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">R_c = \frac {TP_c} {TP_c + FN_c}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.19633em;vertical-align:-0.8360000000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.3139999999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8360000000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p><strong>F 值</strong>（F Measure）是一个<strong>综合指标</strong>，为<strong>精确率</strong>和<strong>召回率</strong>的<strong>调和平均</strong>：</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">ℱ𝑐 = \frac{(1 + 𝛽^2) × P_c × R_c} {𝛽^2 × P_c + R_c}
</p>
<p>其中𝛽 用于平衡<strong>精确率</strong>和<strong>召回率</strong>的重要性，一般取值为1．<strong>𝛽 = 1</strong> 时的<strong>F 值</strong>称为<strong>F1值</strong>，是精确率和召回率的调和平均．</p>
<h4 id="274-宏平均和微平均"><a class="markdownIt-Anchor" href="#274-宏平均和微平均"></a> 2.7.4 宏平均和微平均</h4>
<p>为了计算分类算法在<strong>所有类别</strong>上的<strong>总体</strong>精确率、召回率和F1值，经常使用两种平均方法，分别称为宏平均（Macro Average）和微平均</p>
<p><strong>宏平均</strong>是<strong>每一类</strong>的性能指标的<strong>算术平均值</strong></p>
<p><strong>微平均</strong>是<strong>每一个样本</strong>的性能指标的<strong>算术平均值</strong></p>
<h4 id="275-交叉验证"><a class="markdownIt-Anchor" href="#275-交叉验证"></a> 2.7.5 交叉验证</h4>
<p><strong>交叉验证</strong>（Cross-Validation）是一种比较好的衡量机器学习模型的统计分析方法，可以有效<strong>避免划分训练集和测试集时的随机性</strong>对评价结果造成的影响．我们可以把<strong>原始数据集</strong>平<strong>均分</strong>为<strong>𝐾组</strong>不重复的子集，每次选<strong>𝐾 − 1组</strong>子集作为<strong>训练集</strong>，剩下的<strong>一组</strong>子集作为<strong>验证集</strong>．这样可以进行<strong>𝐾 次试验</strong>并得到𝐾 个模型，将这𝐾 个模型在各自验证集上的<strong>错误率的平均</strong>作为分类器的评价．</p>
<h3 id="28-理论和定理"><a class="markdownIt-Anchor" href="#28-理论和定理"></a> 2.8 理论和定理</h3>
<h4 id="281-pac学习理论"><a class="markdownIt-Anchor" href="#281-pac学习理论"></a> 2.8.1 PAC学习理论</h4>
<p>希望有一套理论能够分析问题难度、计算模型能力，为学习算法提供理论保证，并指导机器学习模型和学习算法的设计．这就是计算学习理论．计算学习理论（Computational Learning Theory）是机器学习的理论基础，其中最基础的理论就是<strong>可能近似正确（Probably Approximately Correct，PAC）学习理论</strong>．</p>
<p>机器学习中一个很<strong>关键</strong>的问题是<strong>期望错误</strong>和<strong>经验错误</strong>之间的<strong>差异</strong>，称为<strong>泛化错误</strong>（Generalization Error）泛化错误可以衡量一个机器学习模型𝑓 是否可以很好地泛化到未知数据．</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>𝒢</mi><mi>D</mi></msub><mo stretchy="false">(</mo><mi>𝑓</mi><mo stretchy="false">)</mo><mo>=</mo><mi>R</mi><mo stretchy="false">(</mo><mi>𝑓</mi><mo stretchy="false">)</mo><mi mathvariant="normal">−</mi><msubsup><mi>R</mi><mi>D</mi><mrow><mi>𝑒</mi><mi>𝑚</mi><mi>𝑝</mi></mrow></msubsup><mo stretchy="false">(</mo><mi>𝑓</mi><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">𝒢_D (𝑓) = R(𝑓) − R^{𝑒𝑚𝑝}_{D} (𝑓).
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathscr" style="margin-right:0.17322em;">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.17322em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.075831em;vertical-align:-0.293531em;"></span><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mclose">)</span><span class="mord">−</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7822999999999999em;"><span style="top:-2.4064690000000004em;margin-left:-0.00773em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span></span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.293531em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mclose">)</span><span class="mord">.</span></span></span></span></span></p>
<p>根据大数定律，当<strong>训练集大小</strong>|𝒟| 趋向于<strong>无穷大</strong>时，<strong>泛化错误趋向于0</strong>，即经验风险趋近于期望风险．</p>
<p><img src="https://i.loli.net/2020/09/12/lokqjURaQbEGe3z.png" alt=""></p>
<p>期望从<strong>有限</strong>的训练<strong>样本</strong>上学习到一个<strong>期望错误为0</strong> 的函数𝑓(𝒙) 是<strong>不切实际</strong>的．因此，需要<strong>降低对学习算法能力的期望</strong>，只要求学习算法可以<strong>以一定的概率</strong>学习到一个<strong>近似正确</strong>的假设，即PAC 学习（PAC Learning）．一个PAC 可学习（PAC-Learnable）的算法是指该学习算法能够在<strong>多项式时间</strong>内从合理数量的训练数据中学习到一个<strong>近似正确</strong>的𝑓(𝒙)．</p>
<p>PAC 学习可以分为两部分：</p>
<ol>
<li><strong>近似正确</strong>（Approximately Correct）：一个假设𝑓 ∈ ℱ 是“近似正确”的，是指其在<strong>泛化错误</strong>𝒢𝒟 (𝑓) <strong>小于一个界限𝜖</strong>．𝜖 一般为0 到1/2之间的数，0 &lt; 𝜖 &lt;1/2．如果𝒢𝒟 (𝑓) 比较大，说明模型不能用来做正确的“预测”．</li>
<li><strong>可能</strong>（Probably）：一个学习算法A有“可能”<strong>以1 − 𝛿 的概率</strong>学习到这样一个“<strong>近似正确</strong>”的假设．𝛿 一般为0 到1/2之间的数，0 &lt; 𝛿 &lt; 1/2</li>
</ol>
<p>PAC 学习可以下面公式描述：</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">𝑃((R(𝑓) − R^{𝑒𝑚𝑝}_D (𝑓)) ≤ 𝜖) ≥ 1 − 𝛿
</p>
<p>如果<strong>固定</strong>𝜖,𝛿，可以反过来计算出需要的样本数量</p>
<p class="katex-block katex-error" title="Error: Font metrics not found for font: .">𝑁(𝜖, 𝛿) ≥ \frac 1 {2𝜖^2} (log |F| + log 2𝛿),
</p>
<p>其中|ℱ| 为假设空间的大小．从上面公式可以看出，<strong>模型越复杂</strong>，即假设空间ℱ 越大，模型的<strong>泛化能力越差</strong>．要达到<strong>相同的泛化能力</strong>，越复杂的模型<strong>需要的样本数量越多</strong>．</p>
<h4 id="282-没有免费的午餐定理"><a class="markdownIt-Anchor" href="#282-没有免费的午餐定理"></a> 2.8.2 没有免费的午餐定理</h4>
<p>没有免费午餐定理证明：对于<strong>基于迭代的最优化算法</strong>，<strong>不存在某种算法对所有问题（有限的搜索空间内）都有效</strong>．</p>
<p>没有免费午餐定理对于机器学习算法也同样适用．不存在一种机器学习算法适合于任何领域或任务．如果有人宣称自己的模型在所有问题上都好于其他模型，那么他肯定是在吹牛．</p>
<h4 id="283-奥卡姆剃刀原理"><a class="markdownIt-Anchor" href="#283-奥卡姆剃刀原理"></a> 2.8.3 奥卡姆剃刀原理</h4>
<p>奥卡姆剃刀（Occam’s Razor）原理是由14世纪逻辑学家William of Occam提出的一个解决问题的法则：<strong>“如无必要，勿增实体”．</strong></p>
<p>奥卡姆剃刀的思想和机器学习中的正则化思想十分类似：<strong>简单的模型泛化能力更好</strong>．如果有两个性能相近的模型，我们应该选择更简单的模型．</p>
<h4 id="284-丑小鸭定理"><a class="markdownIt-Anchor" href="#284-丑小鸭定理"></a> 2.8.4 丑小鸭定理</h4>
<blockquote>
<p>“丑小鸭与白天鹅之间的区别和两只白天鹅之间的区别一样大”．</p>
</blockquote>
<p><strong>世界上不存在相似性的客观标准</strong>，一切相似性的标准都是主观的．如果从体型大小或外貌的角度来看，丑小鸭和白天鹅的区别大于两只白天鹅的区别；但是如果从基因的角度来看，丑小鸭与它父母的差别要小于它父母和其他白天鹅之间的差别．</p>
<h4 id="285-归纳偏置"><a class="markdownIt-Anchor" href="#285-归纳偏置"></a> 2.8.5 归纳偏置</h4>
<p>在机器学习中，<strong>很多学习算法经常会对学习的问题做一些假设</strong>，这些假设就称为<strong>归纳偏置</strong>（Inductive Bias）．比如在最近邻分类器中，我们会假设在特征空间中，一个小的局部区域中的大部分样本同属一类．在朴素贝叶斯分类器中，我们会假设每个特征的条件概率是互相独立的．<br>
归纳偏置在贝叶斯学习中也经常称为<strong>先验</strong>（Prior）．</p>

                                                
            </div>
            <div class="article-footer">
                <blockquote class="mt-2x">
  <ul class="post-copyright list-unstyled">
    
    <li class="post-copyright-link hidden-xs">
      <strong>本文链接：</strong>
      <a href="https://t0ugh.biz/2020/10/15/神经网络与深度学习-2-机器学习概述/" title="[神经网络与深度学习][2][机器学习概述]" target="_blank" rel="external">https://t0ugh.biz/2020/10/15/神经网络与深度学习-2-机器学习概述/</a>
    </li>
    
    <li class="post-copyright-license">
      <strong>版权声明： </strong> 本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！
    </li>
  </ul>
</blockquote>


<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="https://github.com/t0ugh" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="https://i.loli.net/2020/03/21/WAKimNUecFR64uo.jpg" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="https://github.com/t0ugh" target="_blank"><span class="text-dark">T0UGH</span><small class="ml-1x">学生&amp;编程爱好者</small></a></h3>
        <div>很拽很拽很拽很拽很拽很拽很拽很拽</div>
      </div>
    </figure>
  </div>
</div>


            </div>
    </article>
    
        
  <section id="comments">
  	
      <div id="vcomments"></div>
    
  </section>


            
</div>

    <nav class="bar bar-footer clearfix" data-stick-bottom="">
  <div class="bar-inner">
  
  <ul class="pager pull-left">
    
    <li class="prev">
      <a href="/2020/10/29/Flink-1-状态化流处理概述/" title="[Flink][1][状态化流处理概述]"><i class="icon icon-angle-left" aria-hidden="true"></i><span>&nbsp;&nbsp;Newer</span></a>
    </li>
    
    
    <li class="next">
      <a href="/2020/10/15/神经网络与深度学习-1-绪论/" title="[神经网络与深度学习][1][绪论]"><span>Older&nbsp;&nbsp;</span><i class="icon icon-angle-right" aria-hidden="true"></i></a>
    </li>
    
    
  </ul>
  
  
  
  <div class="bar-right">
    
    <div class="share-component" data-sites="weibo,qq,wechat" data-mobile-sites="weibo,qq,qzone"></div>
    
  </div>
  </div>
</nav>
        

            
</main>

  <footer class="footer" itemscope="" itemtype="http://schema.org/WPFooter">
	
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/t0ugh" target="_blank" title="Github" data-toggle="tooltip" data-placement="top"><i class="icon icon-github"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" data-toggle="tooltip" data-placement="top"><i class="icon icon-rss"></i></a></li>
        
    </ul>

    <div class="copyright">
    	
        <div class="publishby">
        	Theme by <a href="https://github.com/cofess" target="_blank"> cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>.
        </div>
    </div>
</footer>
  <script src="//cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>
<script src="/js/plugin.min.js"></script>
<script src="/js/application.js"></script>

    <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>





   




   
    
  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/valine"></script>
  <script type="text/javascript">
  var GUEST = ['nick', 'mail', 'link'];
  var meta = 'nick,mail,link';
  meta = meta.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#vcomments',
    verify: false,
    notify: false,
    appId: 'E1MH6h0YP3yhA0PJsohNBgiT-gzGzoHsz',
    appKey: 'YOiN6zLq3XGfKmlR0b8vyHtN',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: meta,
    pageSize: '10' || 10,
    visitor: false
  });
  </script>

     







</body>
</html>